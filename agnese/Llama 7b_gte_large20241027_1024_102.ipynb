{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a95fda-422d-468f-8216-aa1ed76c8bbc",
   "metadata": {},
   "source": [
    "* Meta Llama 3.1 70B Instruct Neuron\n",
    "*  Mistral 7b\n",
    "*  gte Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7797a1-e8fe-47d6-89bc-2d3cf061b5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade sagemaker jmespath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2e0829-8921-4d5c-b91a-2e3fe7225d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adefe68199d4930bfa38dbae026d5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a JumpStart text generation model:', index=48, layout=Layout(width='max-content')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "\n",
    "dropdown = Dropdown(\n",
    "    options=list_jumpstart_models(\"search_keywords includes Text Generation\"),\n",
    "    value=\"huggingface-llm-mistral-7b-instruct\",\n",
    "    description=\"Select a JumpStart text generation model:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d41d12-22a9-4ec5-9c2a-9ce0bbffbefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model_id,\n",
    "    model_version,\n",
    ") = (\n",
    "    \"meta-textgeneration-llama-2-7b\",\n",
    "    \"2.1.8\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481b0a2e-c774-48a4-a71e-b6d09a6d7753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For forward compatibility, pin to model_version='2.*' in your JumpStartModel or JumpStartEstimator definitions. Note that major version upgrades may have different EULA acceptance terms and input/output signatures.\n",
      "Using vulnerable JumpStart model 'meta-textgeneration-llama-2-7b' and version '2.1.8'.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model = JumpStartModel(model_id=model_id, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1bb6e7-714d-48ad-9806-b98e0dd69d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "# Generate predictor - do not run predictor later in the code\n",
    "predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f33e3e-4e3e-407b-8ca1-24e4232cfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(payload, response):\n",
    "    print(payload[\"inputs\"])\n",
    "    print(f\"> {response[0]['generation']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae1c4aa8-499d-43b4-97ae-9b61927aaa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe the meaning of life is\n",
      ">  to live life.\n",
      "I’m a firm believer that life is a gift. It is a gift that should be cherished, and lived to the fullest.\n",
      "It is a gift that should be lived to the fullest.\n",
      "The meaning of life is to live life to the fullest.\n",
      "\n",
      "==================================\n",
      "\n",
      "CPU times: user 9.08 ms, sys: 4.25 ms, total: 13.3 ms\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    \"inputs\": \"I believe the meaning of life is\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 64,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"return_full_text\": False,\n",
    "    },\n",
    "}\n",
    "try:\n",
    "    response = predictor.predict(payload, custom_attributes=\"accept_eula=true\")  # Changed to true\n",
    "    print_response(payload, response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2cf66b-a7bc-43b6-a24a-fbd1a9fe0d6b",
   "metadata": {},
   "source": [
    "## Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198a0c97-33e0-4a74-a21c-49013f127a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "from langchain_community.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain_community.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain_community.embeddings.sagemaker_endpoint import EmbeddingsContentHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2dea1a-0238-4072-a455-5cc2905b7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "from langchain_community.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "# Additional necessary imports\n",
    "import pandas as pd  # for CSV and data manipulation\n",
    "import numpy as np   # for numerical operations\n",
    "from langchain.document_loaders import CSVLoader  # for loading CSV files\n",
    "from langchain.document_loaders import DataFrameLoader  # alternative for loading pandas DataFrames\n",
    "\n",
    "# Optional but commonly needed imports\n",
    "import boto3  # for AWS services\n",
    "from tqdm import tqdm  # for progress bars\n",
    "import matplotlib.pyplot as plt  # for visualizations\n",
    "#import seaborn as sns  # for enhanced visualizations\n",
    "\n",
    "# For error handling and debugging\n",
    "import logging\n",
    "from typing import Optional, Union  # additional type hints\n",
    "\n",
    "# If you need to handle different file encodings\n",
    "import chardet  # for detecting file encodings\n",
    "\n",
    "# Use the existing endpoint we created\n",
    "#endpoint_name = predictor.endpoint_name  # Get the endpoint name from your existing predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472afc90-2e3d-4258-b057-58451ed06d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available embedding models:\n",
      "Model ID: huggingface-textembedding-all-MiniLM-L6-v2\n",
      "Model ID: huggingface-textembedding-bge-base-en-v1-5\n",
      "Model ID: huggingface-textembedding-bloom-7b1\n",
      "Model ID: huggingface-textembedding-bloom-7b1-fp16\n",
      "Model ID: huggingface-textembedding-gpt-j-6b\n",
      "Model ID: huggingface-textembedding-gpt-j-6b-fp16\n",
      "Model ID: huggingface-textembedding-gte-qwen2-7b-instruct\n",
      "Model ID: huggingface-textembedding-sfr-embedding-2-r\n",
      "Model ID: huggingface-textembedding-sfr-embedding-mistral\n",
      "Model ID: jinaai-embeddings-v2-base-en\n",
      "Model ID: mxnet-tcembedding-robertafin-base-uncased\n",
      "Model ID: mxnet-tcembedding-robertafin-base-wiki-uncased\n",
      "Model ID: mxnet-tcembedding-robertafin-large-uncased\n",
      "Model ID: mxnet-tcembedding-robertafin-large-wiki-uncased\n",
      "Model ID: tensorflow-audioembedding-frill-1\n",
      "Model ID: tensorflow-audioembedding-trill-3\n",
      "Model ID: tensorflow-audioembedding-trill-distilled-3\n",
      "Model ID: tensorflow-audioembedding-trillsson1-1\n",
      "Model ID: tensorflow-audioembedding-trillsson2-1\n",
      "Model ID: tensorflow-audioembedding-trillsson3-1\n",
      "Model ID: tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-m-r101x3-imagenet21k-fv-1\n",
      "Model ID: tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1\n",
      "Model ID: tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1\n",
      "Model ID: tensorflow-icembedding-efficientnet-b0-featurevector-1\n",
      "Model ID: tensorflow-icembedding-efficientnet-b1-featurevector-1\n",
      "Model ID: tensorflow-icembedding-efficientnet-b2-featurevector-1\n",
      "Model ID: tensorflow-icembedding-efficientnet-b3-featurevector-1\n",
      "Model ID: tensorflow-icembedding-efficientnet-b6-featurevector-1\n",
      "Model ID: tensorflow-icembedding-efficientnet-lite0-featurevector-2\n",
      "Model ID: tensorflow-icembedding-efficientnet-lite1-featurevector-2\n",
      "Model ID: tensorflow-icembedding-efficientnet-lite2-featurevector-2\n",
      "Model ID: tensorflow-icembedding-efficientnet-lite3-featurevector-2\n",
      "Model ID: tensorflow-icembedding-efficientnet-lite4-featurevector-2\n",
      "Model ID: tensorflow-icembedding-imagenet-inception-v1-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-inception-v2-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-inception-v3-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-128-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-160-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-192-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-025-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-128-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-160-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-192-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-050-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-128-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-160-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-192-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-075-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-128-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-160-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-192-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v1-100-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-035-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-050-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-075-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-100-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-130-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-mobilenet-v2-140-224-fv-4\n",
      "Model ID: tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4\n",
      "Model ID: tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4\n",
      "Model ID: tensorflow-icembedding-resnet-50-featurevector-1\n",
      "Model ID: tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4\n",
      "Model ID: tensorflow-icembedding-tf2-preview-inception-v3-fv-4\n",
      "Model ID: tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4\n",
      "Model ID: tensorflow-icembedding-tf2-preview-mobilenet-v2-fv-4\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2\n",
      "Model ID: tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2\n",
      "Model ID: tensorflow-tcembedding-bert-wiki-books-mnli-2\n",
      "Model ID: tensorflow-tcembedding-bert-wiki-books-sst2\n",
      "Model ID: tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2\n",
      "Model ID: tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2\n",
      "Model ID: tensorflow-tcembedding-universal-sentc-encoder-cmlm-en-base-1\n",
      "Model ID: tensorflow-tcembedding-universal-sentc-encoder-cmlm-en-large-1\n",
      "Model ID: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1\n",
      "Model ID: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1\n",
      "Model ID: upstage-solar-embedding-large\n",
      "Model ID: voyage-2-embedding\n",
      "Model ID: voyage-code-2-embedding\n",
      "Model ID: voyage-large-2-embedding\n",
      "\n",
      "All available sentence transformer models:\n",
      "Model ID: huggingface-sentencesimilarity-all-MiniLM-L6-v2\n",
      "Model ID: huggingface-sentencesimilarity-bge-base-en\n",
      "Model ID: huggingface-sentencesimilarity-bge-base-en-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-bge-large-en\n",
      "Model ID: huggingface-sentencesimilarity-bge-large-en-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-bge-large-zh-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-bge-m3\n",
      "Model ID: huggingface-sentencesimilarity-bge-small-en\n",
      "Model ID: huggingface-sentencesimilarity-bge-small-en-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-e5-base\n",
      "Model ID: huggingface-sentencesimilarity-e5-base-v2\n",
      "Model ID: huggingface-sentencesimilarity-e5-large\n",
      "Model ID: huggingface-sentencesimilarity-e5-large-v2\n",
      "Model ID: huggingface-sentencesimilarity-e5-small-v2\n",
      "Model ID: huggingface-sentencesimilarity-gte-base\n",
      "Model ID: huggingface-sentencesimilarity-gte-large\n",
      "Model ID: huggingface-sentencesimilarity-gte-small\n",
      "Model ID: huggingface-sentencesimilarity-multilingual-e5-base\n",
      "Model ID: huggingface-sentencesimilarity-multilingual-e5-large\n",
      "Model ID: huggingface-text2text-qcpg-sentences\n",
      "Model ID: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1\n",
      "Model ID: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1\n",
      "\n",
      "All available BGE models:\n",
      "Model ID: huggingface-sentencesimilarity-bge-base-en\n",
      "Model ID: huggingface-sentencesimilarity-bge-base-en-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-bge-large-en\n",
      "Model ID: huggingface-sentencesimilarity-bge-large-en-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-bge-large-zh-v1-5\n",
      "Model ID: huggingface-sentencesimilarity-bge-m3\n",
      "Model ID: huggingface-sentencesimilarity-bge-small-en\n",
      "Model ID: huggingface-sentencesimilarity-bge-small-en-v1-5\n",
      "Model ID: huggingface-textembedding-bge-base-en-v1-5\n",
      "\n",
      "All available models:\n",
      "ai21-contextual-answers\n",
      "ai21-jurassic-2-grande-instruct\n",
      "ai21-jurassic-2-jumbo-instruct\n",
      "ai21-jurassic-2-light\n",
      "ai21-paraphrase\n",
      "ai21-summarization\n",
      "arcee-lite\n",
      "arcee-nova\n",
      "autogluon-classification-ensemble\n",
      "autogluon-forecasting-chronos-t5-base\n",
      "autogluon-forecasting-chronos-t5-large\n",
      "autogluon-forecasting-chronos-t5-small\n",
      "autogluon-regression-ensemble\n",
      "bria-ai-2-2-hd-commercial\n",
      "bria-ai-2-3-commercial\n",
      "bria-ai-2-3-fast-commercial\n",
      "catboost-classification-model\n",
      "catboost-regression-model\n",
      "cohere-command-r-a100\n",
      "cohere-command-r-h100\n",
      "cohere-command-r-plus-a100\n",
      "cohere-command-r-plus-h100\n",
      "cohere-embed-english\n",
      "cohere-embed-light-english\n",
      "cohere-embed-light-multilingual\n",
      "cohere-embed-multilingual\n",
      "cohere-gpt-medium\n",
      "cohere-gpt-xlarge\n",
      "cohere-rerank-english-v2\n",
      "cohere-rerank-multilingual-v2\n",
      "cohere-rerank-nimble-english\n",
      "cohere-rerank-nimble-multi\n",
      "cohere-rerank-v3-english\n",
      "cohere-rerank-v3-multilingual\n",
      "evolutionary-scale-esm3\n",
      "huggingface-asr-whisper-base\n",
      "huggingface-asr-whisper-large\n",
      "huggingface-asr-whisper-large-v2\n",
      "huggingface-asr-whisper-large-v3\n",
      "huggingface-asr-whisper-medium\n",
      "huggingface-asr-whisper-small\n",
      "huggingface-asr-whisper-tiny\n",
      "huggingface-eqa-bert-base-cased\n",
      "huggingface-eqa-bert-base-multilingual-cased\n",
      "huggingface-eqa-bert-base-multilingual-uncased\n",
      "huggingface-eqa-bert-base-uncased\n",
      "huggingface-eqa-bert-large-cased\n",
      "huggingface-eqa-bert-large-cased-whole-word-masking\n",
      "huggingface-eqa-bert-large-uncased\n",
      "huggingface-eqa-bert-large-uncased-whole-word-masking\n",
      "huggingface-eqa-distilbert-base-cased\n",
      "huggingface-eqa-distilbert-base-multilingual-cased\n",
      "huggingface-eqa-distilbert-base-uncased\n",
      "huggingface-eqa-distilroberta-base\n",
      "huggingface-eqa-roberta-base\n",
      "huggingface-eqa-roberta-base-openai-detector\n",
      "huggingface-eqa-roberta-large\n",
      "huggingface-fillmask-bert-base-uncased\n",
      "huggingface-llm-ahxt-litellama-460m-1t\n",
      "huggingface-llm-ai-forever-mgpt\n",
      "huggingface-llm-alpindale-wizard-lm-2-8-22B\n",
      "huggingface-llm-amazon-falconlite\n",
      "huggingface-llm-amazon-falconlite2\n",
      "huggingface-llm-amazon-mistrallite\n",
      "huggingface-llm-aya-101\n",
      "huggingface-llm-berkeley-nest-starling-lm-7b-alpha\n",
      "huggingface-llm-bilingual-rinna-4b-instruction-ppo-bf16\n",
      "huggingface-llm-calm2-7b-chat-bf16\n",
      "huggingface-llm-cognitive-dolphin-29-llama3-8b\n",
      "huggingface-llm-cohereforai-c4ai-command-r-plus\n",
      "huggingface-llm-cultrix-mistraltrix-v1\n",
      "huggingface-llm-dbrx-base\n",
      "huggingface-llm-dbrx-instruct\n",
      "huggingface-llm-dolphin-2-2-1-mistral-7b\n",
      "huggingface-llm-dolphin-2-5-mixtral-8x7b\n",
      "huggingface-llm-dolphin-2-7-mixtral-8x7b\n",
      "huggingface-llm-eleutherai-gpt-neo-1-3b\n",
      "huggingface-llm-eleutherai-gpt-neo-2-7b\n",
      "huggingface-llm-eleutherai-pythia-160m-deduped\n",
      "huggingface-llm-eleutherai-pythia-70m-deduped\n",
      "huggingface-llm-elyza-japanese-llama-2-13b-chat\n",
      "huggingface-llm-elyza-japanese-llama-2-13b-fast-chat\n",
      "huggingface-llm-elyza-japanese-llama-2-7b-chat-bf16\n",
      "huggingface-llm-elyza-japanese-llama-2-7b-fast-chat-bf16\n",
      "huggingface-llm-falcon-180b-bf16\n",
      "huggingface-llm-falcon-180b-chat-bf16\n",
      "huggingface-llm-falcon-40b-bf16\n",
      "huggingface-llm-falcon-40b-instruct-bf16\n",
      "huggingface-llm-falcon-7b-bf16\n",
      "huggingface-llm-falcon-7b-instruct-bf16\n",
      "huggingface-llm-falcon2-11b\n",
      "huggingface-llm-garage-baind-platypus2-7b\n",
      "huggingface-llm-gemma-2b\n",
      "huggingface-llm-gemma-2b-instruct\n",
      "huggingface-llm-gemma-7b\n",
      "huggingface-llm-gemma-7b-instruct\n",
      "huggingface-llm-gradientai-llama-3-8B-instruct-262k\n",
      "huggingface-llm-huggingfaceh4-mistral-7b-sft-alpha\n",
      "huggingface-llm-huggingfaceh4-mistral-7b-sft-beta\n",
      "huggingface-llm-huggingfaceh4-starchat-alpha\n",
      "huggingface-llm-huggingfaceh4-starchat-beta\n",
      "huggingface-llm-huggingfaceh4-zephyr-7b-alpha\n",
      "huggingface-llm-huggingfaceh4-zephyr-7b-beta\n",
      "huggingface-llm-huggingfaceh4-zephyr-orpo-141b-a35b-v01\n",
      "huggingface-llm-llama-3-8b-instruct-gradient\n",
      "huggingface-llm-mistral-7b\n",
      "huggingface-llm-mistral-7b-instruct\n",
      "huggingface-llm-mistral-7b-instruct-v3\n",
      "huggingface-llm-mistral-7b-openorca-gptq\n",
      "huggingface-llm-mistral-7b-v3\n",
      "huggingface-llm-mistralai-mixtral-8x22B-instruct-v0-1\n",
      "huggingface-llm-mixtral-8x22B\n",
      "huggingface-llm-mixtral-8x7b\n",
      "huggingface-llm-mixtral-8x7b-instruct\n",
      "huggingface-llm-mixtral-8x7b-instruct-gptq\n",
      "huggingface-llm-nexaaidev-octopus-v2\n",
      "huggingface-llm-nexusflow-starling-lm-7b-beta\n",
      "huggingface-llm-nousresearch-hermes-2-pro-llama-3-8B\n",
      "huggingface-llm-nousresearch-nous-hermes-2-solar-10-7b\n",
      "huggingface-llm-nousresearch-nous-hermes-llama-2-7b\n",
      "huggingface-llm-nousresearch-nous-hermes-llama2-13b\n",
      "huggingface-llm-nousresearch-yarn-mistral-7b-128k\n",
      "huggingface-llm-nvidia-llama3-chatqa-1-5-70B\n",
      "huggingface-llm-nvidia-llama3-chatqa-1-5-8B\n",
      "huggingface-llm-openlm-research-open-llama-7b-v2\n",
      "huggingface-llm-phi-2\n",
      "huggingface-llm-phi-3-mini-128k-instruct\n",
      "huggingface-llm-phi-3-mini-4k-instruct\n",
      "huggingface-llm-qwen2-0-5b\n",
      "huggingface-llm-qwen2-0-5b-instruct\n",
      "huggingface-llm-qwen2-1-5b\n",
      "huggingface-llm-qwen2-1-5b-instruct\n",
      "huggingface-llm-qwen2-7b\n",
      "huggingface-llm-qwen2-7b-instruct\n",
      "huggingface-llm-rinna-3-6b-instruction-ppo-bf16\n",
      "huggingface-llm-sealion-3b\n",
      "huggingface-llm-sealion-7b\n",
      "huggingface-llm-sealion-7b-instruct\n",
      "huggingface-llm-shenzhi-wang-llama3-8B-chinese-chat\n",
      "huggingface-llm-snowflake-arctic-instruct-vllm\n",
      "huggingface-llm-starcoder\n",
      "huggingface-llm-starcoderbase\n",
      "huggingface-llm-teknium-openhermes-2-mistral-7b\n",
      "huggingface-llm-thebloke-mistral-7b-openorca-awq\n",
      "huggingface-llm-tiiuae-falcon-rw-1b\n",
      "huggingface-llm-tinyllama-1-1b-intermediate-step-1431k-3\n",
      "huggingface-llm-tinyllama-tinyllama-1-1b-chat-v0-6\n",
      "huggingface-llm-tinyllama-tinyllama-1-1b-chat-v1-0\n",
      "huggingface-llm-writer-palmyra-small\n",
      "huggingface-llm-yi-1-5-34b\n",
      "huggingface-llm-yi-1-5-34b-chat\n",
      "huggingface-llm-yi-1-5-6b\n",
      "huggingface-llm-yi-1-5-6b-chat\n",
      "huggingface-llm-yi-1-5-9b\n",
      "huggingface-llm-yi-1-5-9b-chat\n",
      "huggingface-llm-zephyr-7b-gemma\n",
      "huggingface-llmneuron-mistral-7b\n",
      "huggingface-llmneuron-mistral-7b-instruct\n",
      "huggingface-ner-distilbert-base-cased-finetuned-conll03-eng\n",
      "huggingface-ner-distilbert-base-cased-finetuned-conll03-english\n",
      "huggingface-ner-distilbert-base-uncased-finetuned-conll03-eng\n",
      "huggingface-ner-distilbert-base-uncased-finetuned-conll03-english\n",
      "huggingface-sentencesimilarity-all-MiniLM-L6-v2\n",
      "huggingface-sentencesimilarity-bge-base-en\n",
      "huggingface-sentencesimilarity-bge-base-en-v1-5\n",
      "huggingface-sentencesimilarity-bge-large-en\n",
      "huggingface-sentencesimilarity-bge-large-en-v1-5\n",
      "huggingface-sentencesimilarity-bge-large-zh-v1-5\n",
      "huggingface-sentencesimilarity-bge-m3\n",
      "huggingface-sentencesimilarity-bge-small-en\n",
      "huggingface-sentencesimilarity-bge-small-en-v1-5\n",
      "huggingface-sentencesimilarity-e5-base\n",
      "huggingface-sentencesimilarity-e5-base-v2\n",
      "huggingface-sentencesimilarity-e5-large\n",
      "huggingface-sentencesimilarity-e5-large-v2\n",
      "huggingface-sentencesimilarity-e5-small-v2\n",
      "huggingface-sentencesimilarity-gte-base\n",
      "huggingface-sentencesimilarity-gte-large\n",
      "huggingface-sentencesimilarity-gte-small\n",
      "huggingface-sentencesimilarity-multilingual-e5-base\n",
      "huggingface-sentencesimilarity-multilingual-e5-large\n",
      "huggingface-spc-bert-base-cased\n",
      "huggingface-spc-bert-base-multilingual-cased\n",
      "huggingface-spc-bert-base-multilingual-uncased\n",
      "huggingface-spc-bert-base-uncased\n",
      "huggingface-spc-bert-large-cased\n",
      "huggingface-spc-bert-large-cased-whole-word-masking\n",
      "huggingface-spc-bert-large-uncased\n",
      "huggingface-spc-bert-large-uncased-whole-word-masking\n",
      "huggingface-spc-distilbert-base-cased\n",
      "huggingface-spc-distilbert-base-multilingual-cased\n",
      "huggingface-spc-distilbert-base-uncased\n",
      "huggingface-spc-distilroberta-base\n",
      "huggingface-spc-roberta-base\n",
      "huggingface-spc-roberta-base-openai-detector\n",
      "huggingface-spc-roberta-large\n",
      "huggingface-spc-roberta-large-openai-detector\n",
      "huggingface-spc-xlm-clm-ende-1024\n",
      "huggingface-spc-xlm-mlm-ende-1024\n",
      "huggingface-spc-xlm-mlm-enro-1024\n",
      "huggingface-spc-xlm-mlm-tlm-xnli15-1024\n",
      "huggingface-spc-xlm-mlm-xnli15-1024\n",
      "huggingface-summarization-bart-large-cnn-samsum\n",
      "huggingface-summarization-bert-small2bert-cnn-dailymail-summ\n",
      "huggingface-summarization-bert-small2bert-small-finetuned-cnn-daily-mail-summarization\n",
      "huggingface-summarization-bigbird-pegasus-large-arxiv\n",
      "huggingface-summarization-bigbird-pegasus-large-pubmed\n",
      "huggingface-summarization-distilbart-cnn-12-6\n",
      "huggingface-summarization-distilbart-cnn-6-6\n",
      "huggingface-summarization-distilbart-xsum-1-1\n",
      "huggingface-summarization-distilbart-xsum-12-3\n",
      "huggingface-tc-bert-base-cased\n",
      "huggingface-tc-bert-base-multilingual-cased\n",
      "huggingface-tc-bert-base-multilingual-uncased\n",
      "huggingface-tc-bert-base-uncased\n",
      "huggingface-tc-bert-large-cased\n",
      "huggingface-tc-bert-large-cased-whole-word-masking\n",
      "huggingface-tc-bert-large-uncased\n",
      "huggingface-tc-bert-large-uncased-whole-word-masking\n",
      "huggingface-tc-distilbert-base-cased\n",
      "huggingface-tc-distilbert-base-multilingual-cased\n",
      "huggingface-tc-distilbert-base-uncased\n",
      "huggingface-tc-distilroberta-base\n",
      "huggingface-tc-models\n",
      "huggingface-tc-roberta-base\n",
      "huggingface-tc-roberta-base-openai-detector\n",
      "huggingface-tc-roberta-large\n",
      "huggingface-tc-roberta-large-openai-detector\n",
      "huggingface-tc-xlm-clm-ende-1024\n",
      "huggingface-tc-xlm-mlm-ende-1024\n",
      "huggingface-tc-xlm-mlm-enro-1024\n",
      "huggingface-tc-xlm-mlm-tlm-xnli15-1024\n",
      "huggingface-text2text-bart4csc-base-chinese\n",
      "huggingface-text2text-bigscience-t0pp\n",
      "huggingface-text2text-bigscience-t0pp-bnb-int8\n",
      "huggingface-text2text-bigscience-t0pp-fp16\n",
      "huggingface-text2text-flan-t5-base\n",
      "huggingface-text2text-flan-t5-base-samsum\n",
      "huggingface-text2text-flan-t5-large\n",
      "huggingface-text2text-flan-t5-small\n",
      "huggingface-text2text-flan-t5-xl\n",
      "huggingface-text2text-flan-t5-xxl\n",
      "huggingface-text2text-flan-t5-xxl-bnb-int8\n",
      "huggingface-text2text-flan-t5-xxl-fp16\n",
      "huggingface-text2text-flan-ul2-bf16\n",
      "huggingface-text2text-pegasus-paraphrase\n",
      "huggingface-text2text-qcpg-sentences\n",
      "huggingface-text2text-t5-one-line-summary\n",
      "huggingface-textembedding-all-MiniLM-L6-v2\n",
      "huggingface-textembedding-bge-base-en-v1-5\n",
      "huggingface-textembedding-bloom-7b1\n",
      "huggingface-textembedding-bloom-7b1-fp16\n",
      "huggingface-textembedding-gpt-j-6b\n",
      "huggingface-textembedding-gpt-j-6b-fp16\n",
      "huggingface-textembedding-gte-qwen2-7b-instruct\n",
      "huggingface-textembedding-sfr-embedding-2-r\n",
      "huggingface-textembedding-sfr-embedding-mistral\n",
      "huggingface-textgeneration-bloom-1b1\n",
      "huggingface-textgeneration-bloom-1b7\n",
      "huggingface-textgeneration-bloom-560m\n",
      "huggingface-textgeneration-bloomz-1b1\n",
      "huggingface-textgeneration-bloomz-1b7\n",
      "huggingface-textgeneration-bloomz-560m\n",
      "huggingface-textgeneration-distilgpt2\n",
      "huggingface-textgeneration-dolly-v2-12b-bf16\n",
      "huggingface-textgeneration-dolly-v2-3b-bf16\n",
      "huggingface-textgeneration-dolly-v2-7b-bf16\n",
      "huggingface-textgeneration-falcon-40b-bf16\n",
      "huggingface-textgeneration-falcon-40b-instruct-bf16\n",
      "huggingface-textgeneration-falcon-7b-bf16\n",
      "huggingface-textgeneration-falcon-7b-instruct-bf16\n",
      "huggingface-textgeneration-gpt2\n",
      "huggingface-textgeneration-models\n",
      "huggingface-textgeneration-open-llama\n",
      "huggingface-textgeneration1-bloom-176b-int8\n",
      "huggingface-textgeneration1-bloom-3b\n",
      "huggingface-textgeneration1-bloom-3b-fp16\n",
      "huggingface-textgeneration1-bloom-7b1\n",
      "huggingface-textgeneration1-bloom-7b1-fp16\n",
      "huggingface-textgeneration1-bloomz-176b-fp16\n",
      "huggingface-textgeneration1-bloomz-3b-fp16\n",
      "huggingface-textgeneration1-bloomz-7b1-fp16\n",
      "huggingface-textgeneration1-gpt-2-xl\n",
      "huggingface-textgeneration1-gpt-2-xl-fp16\n",
      "huggingface-textgeneration1-gpt-j-6b\n",
      "huggingface-textgeneration1-gpt-j-6b-fp16\n",
      "huggingface-textgeneration1-gpt-neo-1-3b\n",
      "huggingface-textgeneration1-gpt-neo-1-3b-fp16\n",
      "huggingface-textgeneration1-gpt-neo-125m\n",
      "huggingface-textgeneration1-gpt-neo-125m-fp16\n",
      "huggingface-textgeneration1-gpt-neo-2-7b\n",
      "huggingface-textgeneration1-gpt-neo-2-7b-fp16\n",
      "huggingface-textgeneration1-lightgpt\n",
      "huggingface-textgeneration1-mpt-7b-bf16\n",
      "huggingface-textgeneration1-mpt-7b-instruct-bf16\n",
      "huggingface-textgeneration1-mpt-7b-storywriter-bf16\n",
      "huggingface-textgeneration1-redpajama-incite-base-3B-v1-fp16\n",
      "huggingface-textgeneration1-redpajama-incite-base-7B-v1-fp16\n",
      "huggingface-textgeneration1-redpajama-incite-chat-3B-v1-fp16\n",
      "huggingface-textgeneration1-redpajama-incite-chat-7B-v1-fp16\n",
      "huggingface-textgeneration1-redpajama-incite-instruct-3B-v1-fp16\n",
      "huggingface-textgeneration1-redpajama-incite-instruct-3Bv1fp16\n",
      "huggingface-textgeneration1-redpajama-incite-instruct-7B-v1-fp16\n",
      "huggingface-textgeneration1-redpajama-incite-instruct-7B1fp16\n",
      "huggingface-textgeneration2-gpt-neox-20b-fp16\n",
      "huggingface-textgeneration2-gpt-neoxt-chat-base-20b-fp16\n",
      "huggingface-translation-opus-mt-en-es\n",
      "huggingface-translation-opus-mt-en-vi\n",
      "huggingface-translation-opus-mt-mul-en\n",
      "huggingface-translation-t5-base\n",
      "huggingface-translation-t5-large\n",
      "huggingface-translation-t5-small\n",
      "huggingface-txt2img-22h-vintedois-diffusion-v0-1\n",
      "huggingface-txt2img-akikagura-mkgen-diffusion\n",
      "huggingface-txt2img-alxdfy-noggles-fastdb-4800\n",
      "huggingface-txt2img-alxdfy-noggles9000\n",
      "huggingface-txt2img-andite-anything-v4-0\n",
      "huggingface-txt2img-astraliteheart-pony-diffusion-v2\n",
      "huggingface-txt2img-avrik-abstract-anim-spritesheets\n",
      "huggingface-txt2img-aybeeceedee-knollingcase\n",
      "huggingface-txt2img-bingsu-my-k-anything-v3-0\n",
      "huggingface-txt2img-bingsu-my-korean-stable-diffusion-v1-5\n",
      "huggingface-txt2img-buntopsih-novgoranstefanovski\n",
      "huggingface-txt2img-claudfuen-photorealistic-fuen-v1\n",
      "huggingface-txt2img-coder119-vectorartz-diffusion\n",
      "huggingface-txt2img-conflictx-complex-lineart\n",
      "huggingface-txt2img-dallinmackay-cats-musical-diffusion\n",
      "huggingface-txt2img-dallinmackay-jwst-deep-space-diffusion\n",
      "huggingface-txt2img-dallinmackay-tron-legacy-diffusion\n",
      "huggingface-txt2img-dallinmackay-van-gogh-diffusion\n",
      "huggingface-txt2img-dgspitzer-cyberpunk-anime-diffusion\n",
      "huggingface-txt2img-dreamlike-art-dreamlike-diffusion-1-0\n",
      "huggingface-txt2img-eimiss-eimisanimediffusion-1-0v\n",
      "huggingface-txt2img-envvi-inkpunk-diffusion\n",
      "huggingface-txt2img-evel-yoshin\n",
      "huggingface-txt2img-extraphy-mustafa-kemal-ataturk\n",
      "huggingface-txt2img-fffiloni-mr-men-and-little-misses\n",
      "huggingface-txt2img-fictiverse-elrisitas\n",
      "huggingface-txt2img-fictiverse-stable-diffusion-balloonart\n",
      "huggingface-txt2img-fictiverse-stable-diffusion-balloonart-model\n",
      "huggingface-txt2img-fictiverse-stable-diffusion-micro-model\n",
      "huggingface-txt2img-fictiverse-stable-diffusion-microscopic-model\n",
      "huggingface-txt2img-fictiverse-stable-diffusion-papercut-model\n",
      "huggingface-txt2img-fictiverse-stable-diffusion-voxelart-model\n",
      "huggingface-txt2img-haor-evt-v3\n",
      "huggingface-txt2img-hassanblend-hassanblend1-4\n",
      "huggingface-txt2img-idea-ccnl-taiyi-1b-chinese-en-v01\n",
      "huggingface-txt2img-idea-ccnl-taiyi-1b-chinese-v0-1\n",
      "huggingface-txt2img-idea-ccnl-taiyi-stable-diffusion-1b-chinese-en-v0-1\n",
      "huggingface-txt2img-idea-ccnl-taiyi-stable-diffusion-1b-chinese-v0-1\n",
      "huggingface-txt2img-ifansnek-johndiffusion\n",
      "huggingface-txt2img-jersonm89-avatar\n",
      "huggingface-txt2img-jvkape-iconsmi-appiconsmodelforsd\n",
      "huggingface-txt2img-katakana-2d-mix\n",
      "huggingface-txt2img-lacambre-vulvine-look-v02\n",
      "huggingface-txt2img-langboat-guohua-diffusion\n",
      "huggingface-txt2img-linaqruf-anything-v3-0\n",
      "huggingface-txt2img-mikesmodels-waltz-with-bashir-diffusion\n",
      "huggingface-txt2img-mitchtech-klingon-diffusion\n",
      "huggingface-txt2img-mitchtech-vulcan-diffusion\n",
      "huggingface-txt2img-mitsua-mitsua-diffusion-cc0\n",
      "huggingface-txt2img-naclbit-trinart-stable-diffusion-v2\n",
      "huggingface-txt2img-nitrosocke-arcane-diffusion\n",
      "huggingface-txt2img-nitrosocke-archer-diffusion\n",
      "huggingface-txt2img-nitrosocke-classic-anim-diffusion\n",
      "huggingface-txt2img-nitrosocke-elden-ring-diffusion\n",
      "huggingface-txt2img-nitrosocke-future-diffusion\n",
      "huggingface-txt2img-nitrosocke-ghibli-diffusion\n",
      "huggingface-txt2img-nitrosocke-mo-di-diffusion\n",
      "huggingface-txt2img-nitrosocke-nitro-diffusion\n",
      "huggingface-txt2img-nitrosocke-redshift-diffusion\n",
      "huggingface-txt2img-nitrosocke-spider-verse-diffusion\n",
      "huggingface-txt2img-nousr-robo-diffusion\n",
      "huggingface-txt2img-ogkalu-comic-diffusion\n",
      "huggingface-txt2img-openjourney-openjourney\n",
      "huggingface-txt2img-piesposito-openpotionbottle-v2\n",
      "huggingface-txt2img-plasmo-voxel-ish\n",
      "huggingface-txt2img-plasmo-woolitize\n",
      "huggingface-txt2img-progamergov-min-illust-background-diffusion\n",
      "huggingface-txt2img-progamergov-min-illust-backgrounddiffusion\n",
      "huggingface-txt2img-prompthero-linkedin-diffusion\n",
      "huggingface-txt2img-prompthero-openjourney\n",
      "huggingface-txt2img-qilex-magic-diffusion\n",
      "huggingface-txt2img-rabidgremlin-sd-db-epic-space-machine\n",
      "huggingface-txt2img-rayhell-popupbook-diffusion\n",
      "huggingface-txt2img-runwayml-stable-diffusion-v1-5\n",
      "huggingface-txt2img-s3nh-beksinski-style-stable-diffusion\n",
      "huggingface-txt2img-sd-dreambooth-library-original-char-cyclps\n",
      "huggingface-txt2img-sd-dreambooth-library-original-character-cyclps\n",
      "huggingface-txt2img-sd-dreambooth-library-persona-5-shigenori\n",
      "huggingface-txt2img-sd-dreambooth-library-persona-5-shigenori-style\n",
      "huggingface-txt2img-sd-dreambooth-library-seraphm\n",
      "huggingface-txt2img-shirayu-sd-tohoku-v1\n",
      "huggingface-txt2img-thelastben-hrrzg-style-768px\n",
      "huggingface-txt2img-timothepearce-gina-the-cat\n",
      "huggingface-txt2img-trystar-clonediffusion\n",
      "huggingface-txt2img-tuwonga-dbluth\n",
      "huggingface-txt2img-tuwonga-rotoscopee\n",
      "huggingface-txt2img-volrath50-fantasy-card-diffusion\n",
      "huggingface-txt2img-yayab-sd-onepiece-diffusers4\n",
      "huggingface-txt2imgneuron-stabilityai-stable-diffusion-v2-1\n",
      "huggingface-txt2imgneuron-stabilityai-stable-diffusion-xl-base-1-0\n",
      "huggingface-txt2imgneuron-stabilityai-stable-diffusion-xlbase1\n",
      "huggingface-zstc-cross-encoder-nli-deberta-base\n",
      "huggingface-zstc-cross-encoder-nli-distilroberta-base\n",
      "huggingface-zstc-cross-encoder-nli-minilm2-l6-h768\n",
      "huggingface-zstc-cross-encoder-nli-roberta-base\n",
      "huggingface-zstc-digitalepidemiologylab-covid-twit-bert2-mnli\n",
      "huggingface-zstc-digitalepidemiologylab-covid-twitter-bert-v2-mnli\n",
      "huggingface-zstc-eleldar-theme-classification\n",
      "huggingface-zstc-emrecan-bert-base-multilingual-cased-allnli-tr\n",
      "huggingface-zstc-emrecan-bert-base-multilingual-cased-multinli-tr\n",
      "huggingface-zstc-emrecan-bert-base-multilingual-cased-snli-tr\n",
      "huggingface-zstc-emrecan-bert-base-turkish-cased-allnli-tr\n",
      "huggingface-zstc-emrecan-bert-base-turkish-cased-multinli-tr\n",
      "huggingface-zstc-emrecan-bert-base-turkish-cased-snli-tr\n",
      "huggingface-zstc-emrecan-bertbase-mling-cased-allnli-tr\n",
      "huggingface-zstc-emrecan-bertbase-mling-cased-multinli-tr\n",
      "huggingface-zstc-emrecan-cbertbase-turkish-mc4cased-multinlitr\n",
      "huggingface-zstc-emrecan-cbertbase-turkish-mc4cased-snlitr\n",
      "huggingface-zstc-emrecan-cbertbase-turkishmc4-cased-allnlitr\n",
      "huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-allnli-tr\n",
      "huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-multinli-tr\n",
      "huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-snli-tr\n",
      "huggingface-zstc-emrecan-dbase-turkish-cased-allnlitr\n",
      "huggingface-zstc-emrecan-dbertbase-turkish-cased-multinli-tr\n",
      "huggingface-zstc-emrecan-distilbert-base-turkish-cased-allnli-tr\n",
      "huggingface-zstc-emrecan-distilbert-base-turkish-cased-multinli-tr\n",
      "huggingface-zstc-emrecan-distilbert-base-turkish-cased-snli-tr\n",
      "huggingface-zstc-facebook-bart-large-mnli\n",
      "huggingface-zstc-jiva-xlm-roberta-large-it-mnli\n",
      "huggingface-zstc-lighteternal-nli-xlm-r-greek\n",
      "huggingface-zstc-moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli\n",
      "huggingface-zstc-moritzlaurer-deberta3large-mnli-fever\n",
      "huggingface-zstc-moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7\n",
      "huggingface-zstc-moritzlaurer-mdeberta3base-xnli-mling-nli-2m7\n",
      "huggingface-zstc-narsil-bart-large-mnli-opti\n",
      "huggingface-zstc-narsil-deberta-large-mnli-zero-cls\n",
      "huggingface-zstc-navteca-bart-large-mnli\n",
      "huggingface-zstc-recognai-bert-base-spanish-wwm-cased-xnli\n",
      "huggingface-zstc-recognai-zeroshot-selectra-medium\n",
      "huggingface-zstc-recognai-zeroshot-selectra-small\n",
      "ibm-granite-20b-code-instruct-8k\n",
      "ibm-granite-34b-code-instruct-8k\n",
      "ibm-granite-3b-code-instruct-128k\n",
      "ibm-granite-8b-code-instruct-128k\n",
      "jinaai-embeddings-v2-base-en\n",
      "john-snow-labs-summarization-qa\n",
      "lgresearch-exaone\n",
      "lightgbm-classification-model\n",
      "lightgbm-regression-model\n",
      "lighton-lyra-fr\n",
      "lighton-mini-instruct40b\n",
      "meta-tc-llama-prompt-guard-86m\n",
      "meta-textgeneration-llama-2-13b\n",
      "meta-textgeneration-llama-2-13b-f\n",
      "meta-textgeneration-llama-2-70b\n",
      "meta-textgeneration-llama-2-70b-f\n",
      "meta-textgeneration-llama-2-7b\n",
      "meta-textgeneration-llama-2-7b-f\n",
      "meta-textgeneration-llama-3-1-405b-fp8\n",
      "meta-textgeneration-llama-3-1-405b-instruct-fp8\n",
      "meta-textgeneration-llama-3-1-70b\n",
      "meta-textgeneration-llama-3-1-70b-instruct\n",
      "meta-textgeneration-llama-3-1-8b\n",
      "meta-textgeneration-llama-3-1-8b-instruct\n",
      "meta-textgeneration-llama-3-2-1b\n",
      "meta-textgeneration-llama-3-2-1b-instruct\n",
      "meta-textgeneration-llama-3-2-3b\n",
      "meta-textgeneration-llama-3-2-3b-instruct\n",
      "meta-textgeneration-llama-3-70b\n",
      "meta-textgeneration-llama-3-70b-instruct\n",
      "meta-textgeneration-llama-3-8b\n",
      "meta-textgeneration-llama-3-8b-instruct\n",
      "meta-textgeneration-llama-codellama-13b\n",
      "meta-textgeneration-llama-codellama-13b-instruct\n",
      "meta-textgeneration-llama-codellama-13b-python\n",
      "meta-textgeneration-llama-codellama-34b\n",
      "meta-textgeneration-llama-codellama-34b-instruct\n",
      "meta-textgeneration-llama-codellama-34b-python\n",
      "meta-textgeneration-llama-codellama-70b\n",
      "meta-textgeneration-llama-codellama-70b-instruct\n",
      "meta-textgeneration-llama-codellama-70b-python\n",
      "meta-textgeneration-llama-codellama-7b\n",
      "meta-textgeneration-llama-codellama-7b-instruct\n",
      "meta-textgeneration-llama-codellama-7b-python\n",
      "meta-textgeneration-llama-guard-3-1b\n",
      "meta-textgeneration-llama-guard-3-8b\n",
      "meta-textgeneration-llama-guard-7b\n",
      "meta-textgenerationneuron-llama-2-13b\n",
      "meta-textgenerationneuron-llama-2-13b-f\n",
      "meta-textgenerationneuron-llama-2-70b\n",
      "meta-textgenerationneuron-llama-2-70b-f\n",
      "meta-textgenerationneuron-llama-2-7b\n",
      "meta-textgenerationneuron-llama-2-7b-f\n",
      "meta-textgenerationneuron-llama-3-1-70b\n",
      "meta-textgenerationneuron-llama-3-1-70b-instruct\n",
      "meta-textgenerationneuron-llama-3-1-8b\n",
      "meta-textgenerationneuron-llama-3-1-8b-instruct\n",
      "meta-textgenerationneuron-llama-3-2-1b\n",
      "meta-textgenerationneuron-llama-3-2-1b-instruct\n",
      "meta-textgenerationneuron-llama-3-2-3b\n",
      "meta-textgenerationneuron-llama-3-2-3b-instruct\n",
      "meta-textgenerationneuron-llama-3-70b\n",
      "meta-textgenerationneuron-llama-3-70b-instruct\n",
      "meta-textgenerationneuron-llama-3-8b\n",
      "meta-textgenerationneuron-llama-3-8b-instruct\n",
      "meta-textgenerationneuron-llama-codellama-70b\n",
      "meta-textgenerationneuron-llama-codellama-7b\n",
      "meta-textgenerationneuron-llama-codellama-7b-python\n",
      "meta-textgenerationneuron-llama-guard-3-1b\n",
      "meta-textgenerationneuron-llama-guard-3-8b\n",
      "meta-vlm-llama-3-2-11b-vision\n",
      "meta-vlm-llama-3-2-11b-vision-instruct\n",
      "meta-vlm-llama-3-2-90b-vision\n",
      "meta-vlm-llama-3-2-90b-vision-instruct\n",
      "meta-vlm-llama-guard-3-11b-vision\n",
      "model-depth2img-stable-diffusion-2-depth-fp16\n",
      "model-depth2img-stable-diffusion-v1-5-controlnet\n",
      "model-depth2img-stable-diffusion-v1-5-controlnet-fp16\n",
      "model-depth2img-stable-diffusion-v1-5-controlnet-v1-1\n",
      "model-depth2img-stable-diffusion-v1-5-controlnet-v1-1-fp16\n",
      "model-depth2img-stable-diffusion-v2-1-controlnet\n",
      "model-depth2img-stable-diffusion-v2-1-controlnet-fp16\n",
      "model-imagegeneration-stabilityai-stable-diffusion-v2-1\n",
      "model-imagegeneration-stabilityai-stable-diffusion-xl-base-1-0\n",
      "model-inpainting-runwayml-stable-diffusion-inpainting\n",
      "model-inpainting-runwayml-stable-diffusion-inpainting-fp16\n",
      "model-inpainting-stabilityai-stable-diffusion-2-inpainting\n",
      "model-inpainting-stabilityai-stable-diffusion-2-inpainting-fp16\n",
      "model-inpainting-stabilityai-stable-diffusion2-inpainting-fp16\n",
      "model-textgenerationjp-japanese-stablelm-instruct-alpha-7b-v2\n",
      "model-txt2img-stabilityai-stable-diffusion-v1-4\n",
      "model-txt2img-stabilityai-stable-diffusion-v1-4-fp16\n",
      "model-txt2img-stabilityai-stable-diffusion-v2\n",
      "model-txt2img-stabilityai-stable-diffusion-v2-1-base\n",
      "model-txt2img-stabilityai-stable-diffusion-v2-fp16\n",
      "model-upscaling-stabilityai-stable-diffusion-x4-upscaler-fp16\n",
      "mxnet-is-mask-rcnn-fpn-resnet101-v1d-coco\n",
      "mxnet-is-mask-rcnn-fpn-resnet18-v1b-coco\n",
      "mxnet-is-mask-rcnn-fpn-resnet50-v1b-coco\n",
      "mxnet-is-mask-rcnn-resnet18-v1b-coco\n",
      "mxnet-od-faster-rcnn-fpn-resnet101-v1d-coco\n",
      "mxnet-od-faster-rcnn-fpn-resnet50-v1b-coco\n",
      "mxnet-od-faster-rcnn-resnet101-v1d-coco\n",
      "mxnet-od-faster-rcnn-resnet50-v1b-coco\n",
      "mxnet-od-faster-rcnn-resnet50-v1b-voc\n",
      "mxnet-od-ssd-300-vgg16-atrous-coco\n",
      "mxnet-od-ssd-300-vgg16-atrous-voc\n",
      "mxnet-od-ssd-512-mobilenet1-0-coco\n",
      "mxnet-od-ssd-512-mobilenet1-0-voc\n",
      "mxnet-od-ssd-512-resnet50-v1-coco\n",
      "mxnet-od-ssd-512-resnet50-v1-voc\n",
      "mxnet-od-ssd-512-vgg16-atrous-coco\n",
      "mxnet-od-ssd-512-vgg16-atrous-voc\n",
      "mxnet-od-yolo3-darknet53-coco\n",
      "mxnet-od-yolo3-darknet53-voc\n",
      "mxnet-od-yolo3-mobilenet1-0-coco\n",
      "mxnet-od-yolo3-mobilenet1-0-voc\n",
      "mxnet-semseg-fcn-resnet101-ade\n",
      "mxnet-semseg-fcn-resnet101-coco\n",
      "mxnet-semseg-fcn-resnet101-voc\n",
      "mxnet-semseg-fcn-resnet50-ade\n",
      "mxnet-tcembedding-robertafin-base-uncased\n",
      "mxnet-tcembedding-robertafin-base-wiki-uncased\n",
      "mxnet-tcembedding-robertafin-large-uncased\n",
      "mxnet-tcembedding-robertafin-large-wiki-uncased\n",
      "ncsoft-ko-1-3b-ist\n",
      "ncsoft-ko-13b-ist\n",
      "ncsoft-ko-6-4b-ist\n",
      "nomic-embed-image\n",
      "nomic-embed-text\n",
      "pytorch-eqa-bert-base-cased\n",
      "pytorch-eqa-bert-base-multilingual-cased\n",
      "pytorch-eqa-bert-base-multilingual-uncased\n",
      "pytorch-eqa-bert-base-uncased\n",
      "pytorch-eqa-bert-large-cased\n",
      "pytorch-eqa-bert-large-cased-whole-word-masking\n",
      "pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad\n",
      "pytorch-eqa-bert-large-uncased\n",
      "pytorch-eqa-bert-large-uncased-whole-word-masking\n",
      "pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad\n",
      "pytorch-eqa-distilbert-base-cased\n",
      "pytorch-eqa-distilbert-base-multilingual-cased\n",
      "pytorch-eqa-distilbert-base-uncased\n",
      "pytorch-eqa-distilroberta-base\n",
      "pytorch-eqa-roberta-base\n",
      "pytorch-eqa-roberta-base-openai-detector\n",
      "pytorch-eqa-roberta-large\n",
      "pytorch-eqa-roberta-large-openai-detector\n",
      "pytorch-ic-alexnet\n",
      "pytorch-ic-densenet121\n",
      "pytorch-ic-densenet161\n",
      "pytorch-ic-densenet169\n",
      "pytorch-ic-densenet201\n",
      "pytorch-ic-googlenet\n",
      "pytorch-ic-mobilenet-v2\n",
      "pytorch-ic-resnet101\n",
      "pytorch-ic-resnet152\n",
      "pytorch-ic-resnet18\n",
      "pytorch-ic-resnet34\n",
      "pytorch-ic-resnet50\n",
      "pytorch-ic-resnext101-32x8d\n",
      "pytorch-ic-resnext50-32x4d\n",
      "pytorch-ic-shufflenet-v2-x1-0\n",
      "pytorch-ic-squeezenet1-0\n",
      "pytorch-ic-squeezenet1-1\n",
      "pytorch-ic-vgg11\n",
      "pytorch-ic-vgg11-bn\n",
      "pytorch-ic-vgg13\n",
      "pytorch-ic-vgg13-bn\n",
      "pytorch-ic-vgg16\n",
      "pytorch-ic-vgg16-bn\n",
      "pytorch-ic-vgg19\n",
      "pytorch-ic-vgg19-bn\n",
      "pytorch-ic-wide-resnet101-2\n",
      "pytorch-ic-wide-resnet50-2\n",
      "pytorch-od-nvidia-ssd\n",
      "pytorch-od1-fasterrcnn-mobilenet-v3-large-320-fpn\n",
      "pytorch-od1-fasterrcnn-mobilenet-v3-large-fpn\n",
      "pytorch-od1-fasterrcnn-resnet50-fpn\n",
      "pytorch-tabtransformerclassification-model\n",
      "pytorch-tabtransformerregression-model\n",
      "pytorch-textgeneration1-alexa20b\n",
      "sklearn-classification-linear\n",
      "sklearn-classification-snowflake\n",
      "sklearn-regression-linear\n",
      "sklearn-regression-snowflake\n",
      "stabilityai-sdxl-1-0\n",
      "stabilityai-sdxl-beta-0-8\n",
      "tensorflow-audioembedding-frill-1\n",
      "tensorflow-audioembedding-trill-3\n",
      "tensorflow-audioembedding-trill-distilled-3\n",
      "tensorflow-audioembedding-trillsson1-1\n",
      "tensorflow-audioembedding-trillsson2-1\n",
      "tensorflow-audioembedding-trillsson3-1\n",
      "tensorflow-ic-bit-m-r101x1-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-m-r101x1-imagenet21k-classification-1\n",
      "tensorflow-ic-bit-m-r101x3-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-m-r101x3-imagenet21k-classification-1\n",
      "tensorflow-ic-bit-m-r152x4-ilsvrc2012\n",
      "tensorflow-ic-bit-m-r152x4-imagenet21k\n",
      "tensorflow-ic-bit-m-r50x1-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-m-r50x1-imagenet21k-classification-1\n",
      "tensorflow-ic-bit-m-r50x3-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-m-r50x3-imagenet21k-classification-1\n",
      "tensorflow-ic-bit-s-r101x1-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-s-r101x3-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-s-r152x4-ilsvrc2012\n",
      "tensorflow-ic-bit-s-r50x1-ilsvrc2012-classification-1\n",
      "tensorflow-ic-bit-s-r50x3-ilsvrc2012-classification-1\n",
      "tensorflow-ic-cait-m36-384\n",
      "tensorflow-ic-cait-m48-448\n",
      "tensorflow-ic-cait-s24-224\n",
      "tensorflow-ic-cait-s24-384\n",
      "tensorflow-ic-cait-s36-384\n",
      "tensorflow-ic-cait-xs24-384\n",
      "tensorflow-ic-cait-xxs24-224\n",
      "tensorflow-ic-cait-xxs24-384\n",
      "tensorflow-ic-cait-xxs36-224\n",
      "tensorflow-ic-cait-xxs36-384\n",
      "tensorflow-ic-deit-base-distilled-patch16-224\n",
      "tensorflow-ic-deit-base-distilled-patch16-384\n",
      "tensorflow-ic-deit-base-patch16-224\n",
      "tensorflow-ic-deit-base-patch16-384\n",
      "tensorflow-ic-deit-small-distilled-patch16-224\n",
      "tensorflow-ic-deit-small-patch16-224\n",
      "tensorflow-ic-deit-tiny-distilled-patch16-224\n",
      "tensorflow-ic-deit-tiny-patch16-224\n",
      "tensorflow-ic-efficientnet-b0-classification-1\n",
      "tensorflow-ic-efficientnet-b1-classification-1\n",
      "tensorflow-ic-efficientnet-b2-classification-1\n",
      "tensorflow-ic-efficientnet-b3-classification-1\n",
      "tensorflow-ic-efficientnet-b4-classification-1\n",
      "tensorflow-ic-efficientnet-b5-classification-1\n",
      "tensorflow-ic-efficientnet-b6-classification-1\n",
      "tensorflow-ic-efficientnet-b7-classification-1\n",
      "tensorflow-ic-efficientnet-lite0-classification-2\n",
      "tensorflow-ic-efficientnet-lite1-classification-2\n",
      "tensorflow-ic-efficientnet-lite2-classification-2\n",
      "tensorflow-ic-efficientnet-lite3-classification-2\n",
      "tensorflow-ic-efficientnet-lite4-classification-2\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-b0\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-b1\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-b2\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-b3\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-l\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-m\n",
      "tensorflow-ic-efficientnet-v2-imagenet1k-s\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-b0\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-b1\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-b2\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-b3\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b0\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b1\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b2\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-b3\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-l\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-m\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-s\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-ft1k-xl\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-l\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-m\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-s\n",
      "tensorflow-ic-efficientnet-v2-imagenet21k-xl\n",
      "tensorflow-ic-imagenet-inception-resnet-v2-classification-4\n",
      "tensorflow-ic-imagenet-inception-v1-classification-4\n",
      "tensorflow-ic-imagenet-inception-v2-classification-4\n",
      "tensorflow-ic-imagenet-inception-v3-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-025-128-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-025-160-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-025-192-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-025-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-050-128-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-050-160-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-050-192-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-050-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-075-128-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-075-160-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-075-192-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-075-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-100-128-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-100-160-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-100-192-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v1-100-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v2-035-128\n",
      "tensorflow-ic-imagenet-mobilenet-v2-035-160\n",
      "tensorflow-ic-imagenet-mobilenet-v2-035-192\n",
      "tensorflow-ic-imagenet-mobilenet-v2-035-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v2-035-96\n",
      "tensorflow-ic-imagenet-mobilenet-v2-050-128\n",
      "tensorflow-ic-imagenet-mobilenet-v2-050-160\n",
      "tensorflow-ic-imagenet-mobilenet-v2-050-192\n",
      "tensorflow-ic-imagenet-mobilenet-v2-050-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v2-050-96\n",
      "tensorflow-ic-imagenet-mobilenet-v2-075-128\n",
      "tensorflow-ic-imagenet-mobilenet-v2-075-160\n",
      "tensorflow-ic-imagenet-mobilenet-v2-075-192\n",
      "tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v2-075-96\n",
      "tensorflow-ic-imagenet-mobilenet-v2-100-160\n",
      "tensorflow-ic-imagenet-mobilenet-v2-100-192\n",
      "tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v2-100-96\n",
      "tensorflow-ic-imagenet-mobilenet-v2-130-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v2-140-224-classification-4\n",
      "tensorflow-ic-imagenet-mobilenet-v3-large-075-224\n",
      "tensorflow-ic-imagenet-mobilenet-v3-large-100-224\n",
      "tensorflow-ic-imagenet-mobilenet-v3-small-075-224\n",
      "tensorflow-ic-imagenet-mobilenet-v3-small-100-224\n",
      "tensorflow-ic-imagenet-nasnet-large\n",
      "tensorflow-ic-imagenet-nasnet-mobile\n",
      "tensorflow-ic-imagenet-pnasnet-large\n",
      "tensorflow-ic-imagenet-resnet-v1-101-classification-4\n",
      "tensorflow-ic-imagenet-resnet-v1-152-classification-4\n",
      "tensorflow-ic-imagenet-resnet-v1-50-classification-4\n",
      "tensorflow-ic-imagenet-resnet-v2-101-classification-4\n",
      "tensorflow-ic-imagenet-resnet-v2-152-classification-4\n",
      "tensorflow-ic-imagenet-resnet-v2-50-classification-4\n",
      "tensorflow-ic-resnet-50-classification-1\n",
      "tensorflow-ic-swin-base-patch4-window12-384\n",
      "tensorflow-ic-swin-base-patch4-window7-224\n",
      "tensorflow-ic-swin-large-patch4-window12-384\n",
      "tensorflow-ic-swin-large-patch4-window7-224\n",
      "tensorflow-ic-swin-s3-base-224\n",
      "tensorflow-ic-swin-s3-small-224\n",
      "tensorflow-ic-swin-s3-tiny-224\n",
      "tensorflow-ic-swin-small-patch4-window7-224\n",
      "tensorflow-ic-swin-tiny-patch4-window7-224\n",
      "tensorflow-ic-tf2-preview-inception-v3-classification-4\n",
      "tensorflow-ic-tf2-preview-mobilenet-v2-classification-4\n",
      "tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1\n",
      "tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1\n",
      "tensorflow-icembedding-bit-m-r101x3-imagenet21k-fv-1\n",
      "tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1\n",
      "tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1\n",
      "tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1\n",
      "tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1\n",
      "tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1\n",
      "tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1\n",
      "tensorflow-icembedding-efficientnet-b0-featurevector-1\n",
      "tensorflow-icembedding-efficientnet-b1-featurevector-1\n",
      "tensorflow-icembedding-efficientnet-b2-featurevector-1\n",
      "tensorflow-icembedding-efficientnet-b3-featurevector-1\n",
      "tensorflow-icembedding-efficientnet-b6-featurevector-1\n",
      "tensorflow-icembedding-efficientnet-lite0-featurevector-2\n",
      "tensorflow-icembedding-efficientnet-lite1-featurevector-2\n",
      "tensorflow-icembedding-efficientnet-lite2-featurevector-2\n",
      "tensorflow-icembedding-efficientnet-lite3-featurevector-2\n",
      "tensorflow-icembedding-efficientnet-lite4-featurevector-2\n",
      "tensorflow-icembedding-imagenet-inception-v1-featurevector-4\n",
      "tensorflow-icembedding-imagenet-inception-v2-featurevector-4\n",
      "tensorflow-icembedding-imagenet-inception-v3-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-128-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-160-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-192-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-025-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-128-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-160-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-192-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-050-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-128-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-160-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-192-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-075-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-128-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-160-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-192-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v1-100-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-035-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-050-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-075-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-100-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-130-224-fv-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4\n",
      "tensorflow-icembedding-imagenet-mobilenet-v2-140-224-fv-4\n",
      "tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4\n",
      "tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4\n",
      "tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4\n",
      "tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4\n",
      "tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4\n",
      "tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4\n",
      "tensorflow-icembedding-resnet-50-featurevector-1\n",
      "tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4\n",
      "tensorflow-icembedding-tf2-preview-inception-v3-fv-4\n",
      "tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4\n",
      "tensorflow-icembedding-tf2-preview-mobilenet-v2-fv-4\n",
      "tensorflow-od-centernet-hourglass-1024x1024-1\n",
      "tensorflow-od-centernet-hourglass-1024x1024-kpts-1\n",
      "tensorflow-od-centernet-hourglass-512x512-1\n",
      "tensorflow-od-centernet-hourglass-512x512-kpts-1\n",
      "tensorflow-od-centernet-resnet101v1-fpn-512x512-1\n",
      "tensorflow-od-centernet-resnet50v1-fpn-512x512-1\n",
      "tensorflow-od-centernet-resnet50v1-fpn-512x512-kpts-1\n",
      "tensorflow-od-centernet-resnet50v2-512x512-1\n",
      "tensorflow-od-centernet-resnet50v2-512x512-kpts-1\n",
      "tensorflow-od-efficientdet-d0-1\n",
      "tensorflow-od-efficientdet-d1-1\n",
      "tensorflow-od-efficientdet-d2-1\n",
      "tensorflow-od-efficientdet-d3-1\n",
      "tensorflow-od-efficientdet-d4-1\n",
      "tensorflow-od-efficientdet-d5-1\n",
      "tensorflow-od-faster-rcnn-inception-resnet-v2-1024x1024-1\n",
      "tensorflow-od-faster-rcnn-inception-resnet-v2-640x640-1\n",
      "tensorflow-od-faster-rcnn-resnet101-v1-1024x1024-1\n",
      "tensorflow-od-faster-rcnn-resnet101-v1-640x640-1\n",
      "tensorflow-od-faster-rcnn-resnet101-v1-800x1333-1\n",
      "tensorflow-od-faster-rcnn-resnet152-v1-1024x1024-1\n",
      "tensorflow-od-faster-rcnn-resnet152-v1-640x640-1\n",
      "tensorflow-od-faster-rcnn-resnet152-v1-800x1333-1\n",
      "tensorflow-od-faster-rcnn-resnet50-v1-1024x1024-1\n",
      "tensorflow-od-faster-rcnn-resnet50-v1-640x640-1\n",
      "tensorflow-od-faster-rcnn-resnet50-v1-800x1333-1\n",
      "tensorflow-od-retinanet-resnet101-v1-fpn-1024x1024-1\n",
      "tensorflow-od-retinanet-resnet101-v1-fpn-640x640-1\n",
      "tensorflow-od-retinanet-resnet152-v1-fpn-1024x1024-1\n",
      "tensorflow-od-retinanet-resnet152-v1-fpn-640x640-1\n",
      "tensorflow-od-retinanet-resnet50-v1-fpn-1024x1024-1\n",
      "tensorflow-od-retinanet-resnet50-v1-fpn-640x640-1\n",
      "tensorflow-od-ssd-mobilenet-v1-fpn-640x640-1\n",
      "tensorflow-od-ssd-mobilenet-v2-2\n",
      "tensorflow-od-ssd-mobilenet-v2-fpnlite-320x320-1\n",
      "tensorflow-od-ssd-mobilenet-v2-fpnlite-640x640-1\n",
      "tensorflow-od1-ssd-efficientdet-d0-512x512-coco17-tpu-8\n",
      "tensorflow-od1-ssd-efficientdet-d1-640x640-coco17-tpu-8\n",
      "tensorflow-od1-ssd-efficientdet-d2-768x768-coco17-tpu-8\n",
      "tensorflow-od1-ssd-efficientdet-d3-896x896-coco17-tpu-32\n",
      "tensorflow-od1-ssd-mobilenet-v1-fpn-640x640-coco17-tpu-8\n",
      "tensorflow-od1-ssd-mobilenet-v2-fpnlite-320x320-coco17-tpu-8\n",
      "tensorflow-od1-ssd-mobilenet-v2-fpnlite-640x640-coco17-tpu-8\n",
      "tensorflow-od1-ssd-resnet101-v1-fpn-1024x1024-coco17-tpu-8\n",
      "tensorflow-od1-ssd-resnet101-v1-fpn-640x640-coco17-tpu-8\n",
      "tensorflow-od1-ssd-resnet152-v1-fpn-1024x1024-coco17-tpu-8\n",
      "tensorflow-od1-ssd-resnet152-v1-fpn-640x640-coco17-tpu-8\n",
      "tensorflow-od1-ssd-resnet50-v1-fpn-1024x1024-coco17-tpu-8\n",
      "tensorflow-od1-ssd-resnet50-v1-fpn-640x640-coco17-tpu-8\n",
      "tensorflow-spc-bert-en-cased-L-12-H-768-A-12-2\n",
      "tensorflow-spc-bert-en-uncased-L-12-H-768-A-12-2\n",
      "tensorflow-spc-bert-en-uncased-L-24-H-1024-A-16-2\n",
      "tensorflow-spc-bert-en-wwm-cased-L-24-H-1024-A-16-2\n",
      "tensorflow-spc-bert-en-wwm-uncased-L-24-H-1024-A-16-2\n",
      "tensorflow-spc-bert-multi-cased-L-12-H-768-A-12-2\n",
      "tensorflow-spc-electra-base-1\n",
      "tensorflow-spc-electra-small-1\n",
      "tensorflow-spc-experts-bert-pubmed-1\n",
      "tensorflow-spc-experts-bert-wiki-books-1\n",
      "tensorflow-tc-albert-en-base\n",
      "tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2\n",
      "tensorflow-tc-bert-en-cased-L-24-H-1024-A-16-2\n",
      "tensorflow-tc-bert-en-uncased-L-12-H-768-A-12-2\n",
      "tensorflow-tc-bert-en-uncased-L-24-H-1024-A-16-2\n",
      "tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-16-2\n",
      "tensorflow-tc-bert-en-wwm-uncased-L-24-H-1024-A-16-2\n",
      "tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2\n",
      "tensorflow-tc-electra-base-1\n",
      "tensorflow-tc-electra-small-1\n",
      "tensorflow-tc-experts-bert-pubmed-1\n",
      "tensorflow-tc-experts-bert-wiki-books-1\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-10-H-128-A-2\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-10-H-256-A-4\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-10-H-512-A-8\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-10-H-768-A-12\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-12-H-128-A-2\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-12-H-256-A-4\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-12-H-512-A-8\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-12-H-768-A-12\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-2-H-128-A-2\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-2-H-256-A-4\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-2-H-512-A-8\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-2-H-768-A-12\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-4-H-128-A-2\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-4-H-256-A-4\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-4-H-512-A-8\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-4-H-768-A-12\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-6-H-128-A-2\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-6-H-256-A-4\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-6-H-512-A-8\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-6-H-768-A-12\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-8-H-128-A-2\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-8-H-256-A-4\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-8-H-512-A-8\n",
      "tensorflow-tc-small-bert-bert-en-uncased-L-8-H-768-A-12\n",
      "tensorflow-tc-talking-heads-base\n",
      "tensorflow-tc-talking-heads-large\n",
      "tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4\n",
      "tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4\n",
      "tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4\n",
      "tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4\n",
      "tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2\n",
      "tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2\n",
      "tensorflow-tcembedding-bert-wiki-books-mnli-2\n",
      "tensorflow-tcembedding-bert-wiki-books-sst2\n",
      "tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2\n",
      "tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2\n",
      "tensorflow-tcembedding-universal-sentc-encoder-cmlm-en-base-1\n",
      "tensorflow-tcembedding-universal-sentc-encoder-cmlm-en-large-1\n",
      "tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1\n",
      "tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1\n",
      "upstage-document-layout-analysis\n",
      "upstage-document-ocr\n",
      "upstage-solar-embedding-large\n",
      "upstage-solar-mini-chat\n",
      "upstage-solar-mini-chat-ja\n",
      "upstage-solar-mini-chat-ja-quant\n",
      "upstage-solar-mini-chat-quant\n",
      "upstage-solar-pro-preview\n",
      "voyage-2-embedding\n",
      "voyage-code-2-embedding\n",
      "voyage-large-2-embedding\n",
      "voyage-rerank-lite-1-reranker\n",
      "xgboost-classification-model\n",
      "xgboost-classification-snowflake\n",
      "xgboost-regression-model\n",
      "xgboost-regression-snowflake\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# List all available models\n",
    "models = list_jumpstart_models(\n",
    "    region=\"us-east-1\"\n",
    ")\n",
    "\n",
    "print(\"\\nAvailable embedding models:\")\n",
    "for model in models:\n",
    "    # Filter for embedding models\n",
    "    if isinstance(model, str) and (\"embedding\" in model.lower() or \"textembedding\" in model.lower()):\n",
    "        print(f\"Model ID: {model}\")\n",
    "        \n",
    "print(\"\\nAll available sentence transformer models:\")\n",
    "for model in models:\n",
    "    if isinstance(model, str) and \"sentence\" in model.lower():\n",
    "        print(f\"Model ID: {model}\")\n",
    "        \n",
    "print(\"\\nAll available BGE models:\")\n",
    "for model in models:\n",
    "    if isinstance(model, str) and \"bge\" in model.lower():\n",
    "        print(f\"Model ID: {model}\")\n",
    "\n",
    "# Optionally, you can see all available models\n",
    "print(\"\\nAll available models:\")\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804931f2-c5d1-432c-8e52-5317bc3cd57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!LLM Endpoint: meta-textgeneration-llama-2-7b-2024-10-27-06-32-47-486\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_embedding_predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Print both endpoint names\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM Endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictor\u001b[38;5;241m.\u001b[39mendpoint_name)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew E5 Embedding Endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnew_embedding_predictor\u001b[49m\u001b[38;5;241m.\u001b[39mendpoint_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_embedding_predictor' is not defined"
     ]
    }
   ],
   "source": [
    "# Deploy the Mistral model (which you already have)\n",
    "#model_id = \"huggingface-llm-mistral-7b-\"\n",
    "#accept_eula = True\n",
    "#model = JumpStartModel(model_id=model_id, model_version=\"3.9.0\")\n",
    "#predictor = model.deploy(accept_eula=accept_eula, instance_type=\"ml.g5.2xlarge\")\n",
    "\n",
    "# Deploy the GTE-large embedding model\n",
    "model_id_embedding = \"huggingface-sentencesimilarity-gte-large\"\n",
    "model_version = \"1.0.1\"\n",
    "\n",
    "# Deploy new embedding model\n",
    "text_embedding_model = JumpStartModel(\n",
    "    model_id=model_id_embedding, \n",
    "    model_version=model_version\n",
    ")\n",
    "\n",
    "gte_embedding_predictor = text_embedding_model.deploy(\n",
    "    accept_eula=True,\n",
    "    instance_type=\"ml.g5.2xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26b7e40a-3cb7-4cf5-b5bc-599c5ac6536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Endpoint: meta-textgeneration-llama-2-7b-2024-10-27-06-32-47-486\n",
      "Embedding Endpoint: hf-sentencesimilarity-gte-large-2024-10-27-06-53-47-179\n"
     ]
    }
   ],
   "source": [
    "# Print both endpoint names\n",
    "print(\"LLM Endpoint:\", predictor.endpoint_name)\n",
    "print(\"Embedding Endpoint:\", gte_embedding_predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34efaea0-f6fe-4a7c-8879-98a201f2fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants for endpoints\n",
    "LLM_ENDPOINT = \"meta-textgeneration-llama-2-7b-2024-10-27-06-32-47-486\"\n",
    "EMBEDDING_ENDPOINT = \"hf-sentencesimilarity-gte-large-2024-10-27-06-53-47-179\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b94538-aa62-4c7d-bfba-83b698042924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama2ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        payload = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 700,\n",
    "                \"top_p\": 0.9,\n",
    "                \"temperature\": 0.4,\n",
    "                \"return_full_text\": False,  # Important for Llama 2\n",
    "            },\n",
    "        }\n",
    "        input_str = json.dumps(payload)\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b7ba0fe-69ef-4086-88d2-e4edc24f5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "\n",
    "# Create content handler for GTE\n",
    "class GTEContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, text_inputs: List[str], model_kwargs: dict) -> bytes:\n",
    "        # Add the required 'mode' parameter\n",
    "        input_str = json.dumps({\n",
    "            \"text_inputs\": text_inputs,\n",
    "            \"mode\": \"embedding\"  # Add this line\n",
    "        })\n",
    "        return input_str.encode(\"utf-8\")\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        if isinstance(response_json, list):\n",
    "            return response_json\n",
    "        if \"embedding\" in response_json:\n",
    "            return response_json[\"embedding\"]\n",
    "        if \"embeddings\" in response_json:\n",
    "            return response_json[\"embeddings\"]\n",
    "        return response_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f104e90-4471-4042-8a2a-841f3ed2c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker and Endpoints\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=\"meta-textgeneration-llama-2-7b-2024-10-27-06-32-47-486\",\n",
    "    region_name=region,\n",
    "    content_handler=Llama2ContentHandler(),\n",
    "    model_kwargs={\"accept_eula\": True}  # Changed from custom_attributes\n",
    ")\n",
    "\n",
    "sagemaker_embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name=\"hf-sentencesimilarity-gte-large-2024-10-27-06-53-47-179\",\n",
    "    region_name=region,\n",
    "    content_handler=GTEContentHandler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dddfda1-cb06-4c73-ab64-a43d992246a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c pytorch faiss-gpu -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b695df90-a57b-4dd5-be2f-f71535e2505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "import re  # Added this\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import SagemakerEndpoint\n",
    "from langchain_community.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e9b2c69-45ad-4578-a761-c440bd2c87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns: ['title_cleaned', 'recipe_new', 'allergy_type', 'diet_type', 'holiday', 'cuisine_type', 'meal_type', 'ingredients_alternatives']\n",
      "\n",
      "First row of data:\n",
      "title_cleaned                             Roasted Vegetables with Pecan Pesto\n",
      "recipe_new                  Roasted Vegetables with Pecan Pesto\\n1 1/2 pou...\n",
      "allergy_type                                       [Nut, Beet, Fruit, Cheese]\n",
      "diet_type                   [(Vegetarian,80),(Gluten-Free,70),(Dairy-Free,...\n",
      "holiday                                                          Thanksgiving\n",
      "cuisine_type                                                American, Italian\n",
      "meal_type                                                   Dinner, Side dish\n",
      "ingredients_alternatives    Carrots: sweet potatoes, turnips, rutabaga, ra...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Add this before creating the vector store\n",
    "df = pd.read_csv(\"new_recipe_part1.csv\")\n",
    "print(\"CSV columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst row of data:\")\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04c0c9ed-7dad-4ef2-9814-653b590a3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_recipe_system(csv_path: str) -> FAISS:\n",
    "    \"\"\"\n",
    "    Initialize the recipe system by loading CSV data and creating a FAISS vector store.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing recipes\n",
    "        \n",
    "    Returns:\n",
    "        FAISS: Initialized FAISS vector store with recipe embeddings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded {len(df)} recipes from CSV\")\n",
    "        \n",
    "        # Create documents from the DataFrame\n",
    "        documents = []\n",
    "        for _, row in df.iterrows():\n",
    "            # Combine relevant columns into a structured text\n",
    "            text = f\"Title: {row['title_cleaned']}\\n\"\n",
    "            text += f\"Recipe: {row['recipe_new']}\\n\"\n",
    "            text += f\"Allergens: {row['allergy_type']}\\n\"\n",
    "            text += f\"Diet Types: {row['diet_type']}\\n\"\n",
    "            text += f\"Cuisine: {row['cuisine_type']}\\n\"\n",
    "            text += f\"Meal Type: {row['meal_type']}\\n\"\n",
    "            text += f\"Alternative Ingredients: {row['ingredients_alternatives']}\\n\"\n",
    "            \n",
    "            # Create a Document object\n",
    "            doc = Document(page_content=text)\n",
    "            documents.append(doc)\n",
    "        \n",
    "        print(f\"Created {len(documents)} documents\")\n",
    "        \n",
    "        # Split text into chunks if needed\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1024,\n",
    "            chunk_overlap=102,\n",
    "            length_function=len\n",
    "        )\n",
    "        split_docs = text_splitter.split_documents(documents)\n",
    "        print(f\"Split into {len(split_docs)} chunks\")\n",
    "        \n",
    "        # Create and return the FAISS vector store\n",
    "        vectorstore = FAISS.from_documents(\n",
    "            documents=split_docs,\n",
    "            embedding=sagemaker_embeddings\n",
    "        )\n",
    "        \n",
    "        # Verify the vector store was created successfully\n",
    "        test_query = \"test query\"\n",
    "        test_results = vectorstore.similarity_search(test_query, k=1)\n",
    "        if len(test_results) > 0:\n",
    "            print(\"Vector store successfully created and searchable\")\n",
    "            print(\"\\nSample document content:\")\n",
    "            print(test_results[0].page_content[:200], \"...\")\n",
    "        \n",
    "        return vectorstore\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to initialize recipe system: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0efe891d-309c-4e55-953c-2b93b841483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7446 recipes from CSV\n",
      "Created 7446 documents\n",
      "Split into 21529 chunks\n",
      "Vector store successfully created and searchable\n",
      "\n",
      "Sample document content:\n",
      "Note: Some ...\n",
      "Vector store created successfully!\n",
      "\n",
      "Test query result:\n",
      "Title: Chocolate Cake\n",
      "Recipe: Chocolate Cake\n",
      "2 cups sugar\n",
      "1 cup unsweetened cocoa\n",
      "1 cup vegetable shortening\n",
      "1 teaspoon salt\n",
      "2 teaspoons baking powder\n",
      "1 teaspoon baking soda\n",
      "3 cups all-purpose flour\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# First, define the content handler with EULA acceptance\n",
    "from langchain_community.llms.sagemaker_endpoint import LLMContentHandler\n",
    "\n",
    "class Llama2ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        payload = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 700,\n",
    "                \"top_p\": 0.9,\n",
    "                \"temperature\": 0.4,\n",
    "                \"return_full_text\": False\n",
    "            }\n",
    "        }\n",
    "        input_str = json.dumps(payload)\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        try:\n",
    "            response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "            print(\"Raw response:\", response_json)\n",
    "            \n",
    "            # Handle different response formats\n",
    "            if isinstance(response_json, list) and len(response_json) > 0:\n",
    "                if isinstance(response_json[0], dict):\n",
    "                    # Check for 'generation' key first, then 'generated_text'\n",
    "                    if 'generation' in response_json[0]:\n",
    "                        return response_json[0]['generation'].strip()\n",
    "                    return response_json[0].get(\"generated_text\", \"\").strip()\n",
    "                else:\n",
    "                    return str(response_json[0]).strip()\n",
    "            elif isinstance(response_json, dict):\n",
    "                if 'generation' in response_json:\n",
    "                    return response_json['generation'].strip()\n",
    "                return response_json.get(\"generated_text\", \"\").strip()\n",
    "            else:\n",
    "                return str(response_json).strip()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing model output: {e}\")\n",
    "            print(f\"Raw output: {output.read().decode('utf-8')}\")\n",
    "            raise Exception(f\"Failed to parse model output: {e}\")\n",
    "\n",
    "# Initialize the SageMaker endpoint\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=\"meta-textgeneration-llama-2-7b-2024-10-27-06-32-47-486\",\n",
    "    region_name=region,\n",
    "    content_handler=Llama2ContentHandler(),\n",
    "    endpoint_kwargs={\"CustomAttributes\": \"accept_eula=true\"}  # Changed to endpoint_kwargs\n",
    ")\n",
    "\n",
    "# The rest of your code can remain the same\n",
    "def query_recipes(query: str, vectorstore, allergens: Dict[str, List[str]]):\n",
    "    try:\n",
    "        mentioned_allergens = extract_allergens(query, allergens)\n",
    "        print(f\"Allergens found in query: {mentioned_allergens}\")\n",
    "        \n",
    "        # Get relevant recipes\n",
    "        docs = vectorstore.similarity_search(query, k=20)\n",
    "        print(f\"Found {len(docs)} relevant recipes\")\n",
    "        \n",
    "        if mentioned_allergens:\n",
    "            filtered_docs = []\n",
    "            for doc in docs:\n",
    "                content_lower = doc.page_content.lower()\n",
    "                if not any(allergen.lower() in content_lower for allergen in mentioned_allergens):\n",
    "                    filtered_docs.append(doc)\n",
    "            docs = filtered_docs[:10]\n",
    "            print(f\"Filtered to {len(docs)} documents after removing allergen-containing content\")\n",
    "        \n",
    "        # Create a more structured prompt\n",
    "        prompt = f\"\"\"[INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
    "\n",
    "REQUEST: {query}\n",
    "ALLERGIES TO AVOID: {', '.join(mentioned_allergens) if mentioned_allergens else 'None'}\n",
    "\n",
    "Here are some relevant recipes for reference:\n",
    "{docs[0].page_content if docs else 'No reference recipes available'}\n",
    "\n",
    "Please provide:\n",
    "1. List of ingredients with measurements\n",
    "2. Step-by-step instructions\n",
    "3. Any tips or variations\n",
    "\n",
    "Format the recipe clearly with sections for ingredients and instructions.\n",
    "[/INST]\"\"\"\n",
    "        \n",
    "        print(\"\\nGenerating recipe...\")\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            print(\"\\nResponse received, length:\", len(response) if response else 0)\n",
    "            \n",
    "            if not response or len(response) < 50:\n",
    "                print(\"Response is too short, retrying...\")\n",
    "                retry_prompt = f\"\"\"[INST] Create a simple recipe for {query}. Include:\n",
    "1. Ingredients list with measurements\n",
    "2. Step-by-step cooking instructions\n",
    "[/INST]\"\"\"\n",
    "                response = llm.invoke(retry_prompt)\n",
    "            \n",
    "            return response if response else \"Error: Empty response from model\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during recipe generation: {str(e)}\")\n",
    "            return f\"Error generating recipe: {str(e)}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in query_recipes: {str(e)}\")\n",
    "        return f\"Error processing recipe query: {str(e)}\"\n",
    "        \n",
    "# Also add the extract_allergens function\n",
    "def extract_allergens(query: str, allergens: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Extract mentioned allergens from the query.\"\"\"\n",
    "    mentioned_allergens = []\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    for category, allergen_list in allergens.items():\n",
    "        for allergen in allergen_list:\n",
    "            if allergen.lower() in query_lower:\n",
    "                mentioned_allergens.append(allergen)\n",
    "    \n",
    "    return mentioned_allergens\n",
    "\n",
    "# Initialization code rwith new embedding\n",
    "try:\n",
    "    csv_path = \"new_recipe_part1.csv\"\n",
    "    vectorstore = initialize_recipe_system(csv_path)\n",
    "    print(\"Vector store created successfully!\")\n",
    "    \n",
    "    # Test the vector store\n",
    "    allergens_dict = {\n",
    "        \"common\": [\"milk\", \"eggs\", \"peanuts\", \"tree nuts\", \"soy\", \"wheat\", \"fish\", \"shellfish\"],\n",
    "        \"additional\": [\"sesame\", \"gluten\", \"dairy\"]\n",
    "    }\n",
    "    \n",
    "    # Simple test query\n",
    "    test_query = \"chocolate cake\"\n",
    "    similar_docs = vectorstore.similarity_search(test_query, k=1)\n",
    "    print(\"\\nTest query result:\")\n",
    "    print(similar_docs[0].page_content[:200] if similar_docs else \"No results found\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during initialization: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a42168be-d12d-4887-9099-c69db60cabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergens found in query: ['tree nuts']\n",
      "Found 20 relevant recipes\n",
      "Filtered to 10 documents after removing allergen-containing content\n",
      "\n",
      "Generating recipe...\n",
      "Raw response: [{'generation': '\\n\\n```\\n\\n### [Sushi](./sushi.md)\\n\\n[INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I am allergic to nuts and tree nuts. Can you suggest a Sushi recipe that is completely nut-free?\\nALLERGIES TO AVOID: tree nuts\\n\\nHere are some relevant recipes for reference:\\nAllergens: [Nut, Fruit, Spice, Fish/Shellfish, Dairy, Grain, Peanut, Tree nut, Soy, Wheat]\\nDiet Types: [(Vegetarian,90),(Gluten-Free,80),(Dairy-Free,70),(Lactovegetarians,60),(OvoVegetarian,50),(Paleo,40),(Fruitarian,30),(Pescetarian,20),(Pollotarian,10),(Atkins,10),(SouthBeach,10)\\nCuisine: Sushi\\nMeal Type: Dinner, Lunch\\nAlternative Ingredients: Serrano peppers: jalapeno, habanero, Thai chili\\nAnaheim peppers: bell peppers, padrón peppers\\nShallot: scallions, spring onions\\nLemongrass: galangal, kaffir lime leaves\\nGinger: turmeric, cumin\\nAnchovy paste: fish sauce, soy sauce\\nCurry powder: cumin, coriander, turmeric\\nCornstarch: flour, arrowroot powder\\nChicken: beef, pork, tofu\\nRice: quinoa, barley\\nBacon: prosciutto, pancetta\\nTomatoes: mushrooms, eggplant\\nGreen onions: scallions, chives\\nRed bell pepper: capsicum, paprika\\nEggs: duck eggs, goose eggs\\nRaisins: dates, prunes\\nPeanuts: cashews, almonds\\nCoconut: macadamia nuts, pecans\\nSpicy Pear Chutney: mango chutney, tamarind paste\\n\\nPlease provide:\\n1. List of ingredients with measurements\\n2. Step-by-step instructions\\n3. Any tips or variations\\n\\nFormat the recipe clearly with sections for ingredients and instructions.\\n[/INST]\\n\\n```\\n\\n### [Tacos](./tacos.md)\\n\\n[INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I am allergic to nuts and tree nuts. Can you suggest a Tacos recipe that is completely nut-free?\\nALLERGIES TO AVOID: tree nuts\\n\\nHere are some relevant recipes for reference:\\nAllergens: [Nut, Fruit, Spice, Fish/Shellfish, Dairy, Grain, Peanut, Tree nut, Soy, Wheat]\\nDiet Types'}]\n",
      "\n",
      "Response received, length: 1878\n",
      "```\n",
      "\n",
      "### [Sushi](./sushi.md)\n",
      "\n",
      "[INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I am allergic to nuts and tree nuts. Can you suggest a Sushi recipe that is completely nut-free?\n",
      "ALLERGIES TO AVOID: tree nuts\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "Allergens: [Nut, Fruit, Spice, Fish/Shellfish, Dairy, Grain, Peanut, Tree nut, Soy, Wheat]\n",
      "Diet Types: [(Vegetarian,90),(Gluten-Free,80),(Dairy-Free,70),(Lactovegetarians,60),(OvoVegetarian,50),(Paleo,40),(Fruitarian,30),(Pescetarian,20),(Pollotarian,10),(Atkins,10),(SouthBeach,10)\n",
      "Cuisine: Sushi\n",
      "Meal Type: Dinner, Lunch\n",
      "Alternative Ingredients: Serrano peppers: jalapeno, habanero, Thai chili\n",
      "Anaheim peppers: bell peppers, padrón peppers\n",
      "Shallot: scallions, spring onions\n",
      "Lemongrass: galangal, kaffir lime leaves\n",
      "Ginger: turmeric, cumin\n",
      "Anchovy paste: fish sauce, soy sauce\n",
      "Curry powder: cumin, coriander, turmeric\n",
      "Cornstarch: flour, arrowroot powder\n",
      "Chicken: beef, pork, tofu\n",
      "Rice: quinoa, barley\n",
      "Bacon: prosciutto, pancetta\n",
      "Tomatoes: mushrooms, eggplant\n",
      "Green onions: scallions, chives\n",
      "Red bell pepper: capsicum, paprika\n",
      "Eggs: duck eggs, goose eggs\n",
      "Raisins: dates, prunes\n",
      "Peanuts: cashews, almonds\n",
      "Coconut: macadamia nuts, pecans\n",
      "Spicy Pear Chutney: mango chutney, tamarind paste\n",
      "\n",
      "Please provide:\n",
      "1. List of ingredients with measurements\n",
      "2. Step-by-step instructions\n",
      "3. Any tips or variations\n",
      "\n",
      "Format the recipe clearly with sections for ingredients and instructions.\n",
      "[/INST]\n",
      "\n",
      "```\n",
      "\n",
      "### [Tacos](./tacos.md)\n",
      "\n",
      "[INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I am allergic to nuts and tree nuts. Can you suggest a Tacos recipe that is completely nut-free?\n",
      "ALLERGIES TO AVOID: tree nuts\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "Allergens: [Nut, Fruit, Spice, Fish/Shellfish, Dairy, Grain, Peanut, Tree nut, Soy, Wheat]\n",
      "Diet Types\n"
     ]
    }
   ],
   "source": [
    "# allergy = Nut & Treenut / cousine = Thai\n",
    "# Example Usage\n",
    "query = \"I am allergic to nuts and tree nuts. Can you suggest a Thai curry recipe that is completely nut-free?\"\n",
    "response = query_recipes(query, vectorstore, allergens_dict)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb7ea133-15a9-4657-9ff2-8767935a2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergens found in query: ['gluten']\n",
      "Found 20 relevant recipes\n",
      "Filtered to 5 documents after removing allergen-containing content\n",
      "\n",
      "Generating recipe...\n",
      "Raw response: [{'generation': \"\\n\\n### [VEG] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I'm a vegan. Please suggest a recipe for a vegan-friendly version of a traditional Italian dish.\\nALLERGIES TO AVOID: gluten\\n\\nHere are some relevant recipes for reference:\\n7. Spoon vinaigrette over grilled polenta.\\nAllergens: [Milk, Egg, Tree nut, Wheat, Soy, Fish, Shellfish]\\nDiet Types: [(Vegetarian,90),(Dairy-Free,80),(Lactovegetarians,70),(OvoVegetarian,60),(Paleo,40)]\\nCuisine: American, Italian\\nMeal Type: Dinner, Appetizer\\nAlternative Ingredients: Butter: vegetable shortening, coconut oil\\nChicken Stock or Water: beef broth, fish broth, vegetable broth\\nPolenta: cornmeal, quinoa, rice\\nCoarse Kosher Salt: Himalayan pink salt, flaky sea salt\\nCorn Kernels: bell peppers, cherry tomatoes, sliced zucchini\\nFreshly Grated Parmesan: nutmeg, cinnamon\\nOlive Oil: avocado oil, grapeseed oil, walnut oil\\nSalt and Freshly Grounded Pepper: smoked paprika, cumin, coriander\\nMorel Vinaigrette: balsamic vinegar, red wine vinegar, white wine vinegar\\nAged Sherry Vinegar: apple cider vinegar, white wine vinegar, balsamic vinegar\\nShallot: scallions, spring onions, leeks\\nDijon Mustard: whole grain mustard, brown mustard, spicy mustard\\n\\nPlease provide:\\n1. List of ingredients with measurements\\n2. Step-by-step instructions\\n3. Any tips or variations\\n\\nFormat the recipe clearly with sections for ingredients and instructions.\\n[/VEG]\\n\\n### [VEG] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I'm a vegan. Please suggest a recipe for a vegan-friendly version of a traditional Italian dish.\\nALLERGIES TO AVOID: gluten\\n\\nHere are some relevant recipes for reference:\\n7. Spoon vinaigrette over grilled polenta.\\nAllergens: [Milk, Egg, Tree nut, Wheat, Soy, Fish, Shellfish]\\nDiet Types: [(Vegetarian,90),(Dairy-Free,80),(Lactovegetarians,70),(OvoVegetarian,60),(Paleo,40)]\\nCuisine: American, Italian\\nMeal Type: Dinner, Appetizer\\nAlternative Ingredients: Butter: vegetable shortening\"}]\n",
      "\n",
      "Response received, length: 1999\n",
      "### [VEG] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I'm a vegan. Please suggest a recipe for a vegan-friendly version of a traditional Italian dish.\n",
      "ALLERGIES TO AVOID: gluten\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "7. Spoon vinaigrette over grilled polenta.\n",
      "Allergens: [Milk, Egg, Tree nut, Wheat, Soy, Fish, Shellfish]\n",
      "Diet Types: [(Vegetarian,90),(Dairy-Free,80),(Lactovegetarians,70),(OvoVegetarian,60),(Paleo,40)]\n",
      "Cuisine: American, Italian\n",
      "Meal Type: Dinner, Appetizer\n",
      "Alternative Ingredients: Butter: vegetable shortening, coconut oil\n",
      "Chicken Stock or Water: beef broth, fish broth, vegetable broth\n",
      "Polenta: cornmeal, quinoa, rice\n",
      "Coarse Kosher Salt: Himalayan pink salt, flaky sea salt\n",
      "Corn Kernels: bell peppers, cherry tomatoes, sliced zucchini\n",
      "Freshly Grated Parmesan: nutmeg, cinnamon\n",
      "Olive Oil: avocado oil, grapeseed oil, walnut oil\n",
      "Salt and Freshly Grounded Pepper: smoked paprika, cumin, coriander\n",
      "Morel Vinaigrette: balsamic vinegar, red wine vinegar, white wine vinegar\n",
      "Aged Sherry Vinegar: apple cider vinegar, white wine vinegar, balsamic vinegar\n",
      "Shallot: scallions, spring onions, leeks\n",
      "Dijon Mustard: whole grain mustard, brown mustard, spicy mustard\n",
      "\n",
      "Please provide:\n",
      "1. List of ingredients with measurements\n",
      "2. Step-by-step instructions\n",
      "3. Any tips or variations\n",
      "\n",
      "Format the recipe clearly with sections for ingredients and instructions.\n",
      "[/VEG]\n",
      "\n",
      "### [VEG] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I'm a vegan. Please suggest a recipe for a vegan-friendly version of a traditional Italian dish.\n",
      "ALLERGIES TO AVOID: gluten\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "7. Spoon vinaigrette over grilled polenta.\n",
      "Allergens: [Milk, Egg, Tree nut, Wheat, Soy, Fish, Shellfish]\n",
      "Diet Types: [(Vegetarian,90),(Dairy-Free,80),(Lactovegetarians,70),(OvoVegetarian,60),(Paleo,40)]\n",
      "Cuisine: American, Italian\n",
      "Meal Type: Dinner, Appetizer\n",
      "Alternative Ingredients: Butter: vegetable shortening\n"
     ]
    }
   ],
   "source": [
    "# allergy = Gluten (Wheat) / cousine = Italian\n",
    "# Example Usage\n",
    "query = \"I have celiac disease. Please suggest an Italian polenta-based recipe that's naturally gluten-free.\"\n",
    "response = query_recipes(query, vectorstore, allergens_dict)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "797fc688-3f02-4198-9844-ed2259484c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergens found in query: ['milk', 'eggs']\n",
      "Found 20 relevant recipes\n",
      "Filtered to 2 documents after removing allergen-containing content\n",
      "\n",
      "Generating recipe...\n",
      "Raw response: [{'generation': \"\\n\\n### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: Looking for an ice cream alternative - I'm allergic to milk and eggs. Can you suggest a frozen dessert recipe?\\nALLERGIES TO AVOID: milk, eggs\\n\\nHere are some relevant recipes for reference:\\nAllergens: [Fruit, Nut, Dairy, Sugar, Pastry, Egg]\\nDiet Types: [(Vegan,80),(Fruitarian,70),(Paleo,60),(LowFODMAP,50)]\\nCuisine: American, French\\nMeal Type: Dessert, High Tea\\nAlternative Ingredients: Pineapple rings: mango chunks, kiwi slices, papaya cubes\\nGinger: turmeric, cinnamon, nutmeg\\nSea salt: kosher salt, Himalayan pink salt\\nAgave syrup: honey, maple syrup, coconut sugar\\nPuff pastry: puffed rice, crispy rice, gluten-free pastry\\nEgg: chicken egg, duck egg, quail egg\\nGranulated sugar: brown sugar, raw sugar, coconut sugar\\nVanilla ice cream: coconut ice cream, cashew ice cream, almond ice cream\\nCaramel sauce: chocolate sauce, peanut butter sauce, maple syrup\\nToasted almonds: chopped nuts, roasted cashews, sunflower seeds\\n\\nPlease provide:\\n1. List of ingredients with measurements\\n2. Step-by-step instructions\\n3. Any tips or variations\\n\\nFormat the recipe clearly with sections for ingredients and instructions.\\n[/INST]\\n\\n### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: Looking for an ice cream alternative - I'm allergic to milk and eggs. Can you suggest a frozen dessert recipe?\\nALLERGIES TO AVOID: milk, eggs\\n\\nHere are some relevant recipes for reference:\\nAllergens: [Fruit, Nut, Dairy, Sugar, Pastry, Egg]\\nDiet Types: [(Vegan,80),(Fruitarian,70),(Paleo,60),(LowFODMAP,50)]\\nCuisine: American, French\\nMeal Type: Dessert, High Tea\\nAlternative Ingredients: Pineapple rings: mango chunks, kiwi slices, papaya cubes\\nGinger: turmeric, cinnamon, nutmeg\\nSea salt: kosher salt, Himalayan pink salt\\nAgave syrup: honey, maple syrup, coconut sugar\\nPuff pastry: puffed rice, crispy rice, gluten-free pastry\\nEgg: chicken egg, duck egg, quail egg\"}]\n",
      "\n",
      "Response received, length: 1978\n",
      "### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: Looking for an ice cream alternative - I'm allergic to milk and eggs. Can you suggest a frozen dessert recipe?\n",
      "ALLERGIES TO AVOID: milk, eggs\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "Allergens: [Fruit, Nut, Dairy, Sugar, Pastry, Egg]\n",
      "Diet Types: [(Vegan,80),(Fruitarian,70),(Paleo,60),(LowFODMAP,50)]\n",
      "Cuisine: American, French\n",
      "Meal Type: Dessert, High Tea\n",
      "Alternative Ingredients: Pineapple rings: mango chunks, kiwi slices, papaya cubes\n",
      "Ginger: turmeric, cinnamon, nutmeg\n",
      "Sea salt: kosher salt, Himalayan pink salt\n",
      "Agave syrup: honey, maple syrup, coconut sugar\n",
      "Puff pastry: puffed rice, crispy rice, gluten-free pastry\n",
      "Egg: chicken egg, duck egg, quail egg\n",
      "Granulated sugar: brown sugar, raw sugar, coconut sugar\n",
      "Vanilla ice cream: coconut ice cream, cashew ice cream, almond ice cream\n",
      "Caramel sauce: chocolate sauce, peanut butter sauce, maple syrup\n",
      "Toasted almonds: chopped nuts, roasted cashews, sunflower seeds\n",
      "\n",
      "Please provide:\n",
      "1. List of ingredients with measurements\n",
      "2. Step-by-step instructions\n",
      "3. Any tips or variations\n",
      "\n",
      "Format the recipe clearly with sections for ingredients and instructions.\n",
      "[/INST]\n",
      "\n",
      "### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: Looking for an ice cream alternative - I'm allergic to milk and eggs. Can you suggest a frozen dessert recipe?\n",
      "ALLERGIES TO AVOID: milk, eggs\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "Allergens: [Fruit, Nut, Dairy, Sugar, Pastry, Egg]\n",
      "Diet Types: [(Vegan,80),(Fruitarian,70),(Paleo,60),(LowFODMAP,50)]\n",
      "Cuisine: American, French\n",
      "Meal Type: Dessert, High Tea\n",
      "Alternative Ingredients: Pineapple rings: mango chunks, kiwi slices, papaya cubes\n",
      "Ginger: turmeric, cinnamon, nutmeg\n",
      "Sea salt: kosher salt, Himalayan pink salt\n",
      "Agave syrup: honey, maple syrup, coconut sugar\n",
      "Puff pastry: puffed rice, crispy rice, gluten-free pastry\n",
      "Egg: chicken egg, duck egg, quail egg\n"
     ]
    }
   ],
   "source": [
    "# allergy = Milk & Egg / cousine = Dessert\n",
    "# Example Usage\n",
    "query = \"Looking for an ice cream alternative - I'm allergic to milk and eggs. Can you suggest a frozen dessert recipe?\"\n",
    "response = query_recipes(query, vectorstore, allergens_dict)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0f140a2-4874-490d-b104-1ac96eb4fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergens found in query: ['soy']\n",
      "Found 20 relevant recipes\n",
      "Filtered to 3 documents after removing allergen-containing content\n",
      "\n",
      "Generating recipe...\n",
      "Raw response: [{'generation': \"\\n\\n### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I am allergic to soy and eat vegan. Can you share a recipe for a protein-rich main dish using legumes instead of soy products?\\nALLERGIES TO AVOID: soy\\n\\nHere are some relevant recipes for reference:\\n14. Add cilantro, season with salt, and toss.\\n15. In a small bowl, whisk apricot preserves, water, vinegar, red pepper flakes, and salt.\\n16. Serve tofu with snap pea salad and apricot dipping sauce.\\nAllergens: [Cow's Milk, Eggs, Coconut]\\nDiet Types: [(Vegan,90),(Vegetarian,90),(Gluten-Free,80),(Dairy-Free,70),(Fruitarian,60),(Paleo,50)]\\nCuisine: American, Asian\\nMeal Type: Dinner, Appetizer\\nAlternative Ingredients: Tofu: tempeh, seitan, vegan sausage\\nKosher salt: sea salt\\nFlour: all-purpose flour, whole wheat flour\\nEggs: flaxseed, chia seeds, aquafaba\\nRed pepper flakes: cayenne pepper, paprika\\nCoconut: cashews, macadamia nuts\\nBreadcrumbs: panko crumbs, crushed crackers\\nOlive oil: avocado oil, grapeseed oil\\nRice vinegar: apple cider vinegar, white wine vinegar\\nSugar snap peas: snow peas, green beans\\nCilantro: parsley, basil, dill\\nApricot preserves: fig jam, quince jelly\\n\\nPlease provide:\\n1. List of ingredients with measurements\\n2. Step-by-step instructions\\n3. Any tips or variations\\n\\nFormat the recipe clearly with sections for ingredients and instructions.\\n[/INST]\\n\\n### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I am allergic to soy and eat vegan. Can you share a recipe for a protein-rich main dish using legumes instead of soy products?\\nALLERGIES TO AVOID: soy\\n\\nHere are some relevant recipes for reference:\\n14. Add cilantro, season with salt, and toss.\\n15. In a small bowl, whisk apricot preserves, water, vinegar, red pepper flakes, and salt.\\n16. Serve tofu with snap pea salad and apricot dipping sauce.\\nAllergens: [Cow's Milk, Eggs, Coconut]\\nDiet Types: [(Vegan,90),(Vegetarian,90),(\"}]\n",
      "\n",
      "Response received, length: 1947\n",
      "### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I am allergic to soy and eat vegan. Can you share a recipe for a protein-rich main dish using legumes instead of soy products?\n",
      "ALLERGIES TO AVOID: soy\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "14. Add cilantro, season with salt, and toss.\n",
      "15. In a small bowl, whisk apricot preserves, water, vinegar, red pepper flakes, and salt.\n",
      "16. Serve tofu with snap pea salad and apricot dipping sauce.\n",
      "Allergens: [Cow's Milk, Eggs, Coconut]\n",
      "Diet Types: [(Vegan,90),(Vegetarian,90),(Gluten-Free,80),(Dairy-Free,70),(Fruitarian,60),(Paleo,50)]\n",
      "Cuisine: American, Asian\n",
      "Meal Type: Dinner, Appetizer\n",
      "Alternative Ingredients: Tofu: tempeh, seitan, vegan sausage\n",
      "Kosher salt: sea salt\n",
      "Flour: all-purpose flour, whole wheat flour\n",
      "Eggs: flaxseed, chia seeds, aquafaba\n",
      "Red pepper flakes: cayenne pepper, paprika\n",
      "Coconut: cashews, macadamia nuts\n",
      "Breadcrumbs: panko crumbs, crushed crackers\n",
      "Olive oil: avocado oil, grapeseed oil\n",
      "Rice vinegar: apple cider vinegar, white wine vinegar\n",
      "Sugar snap peas: snow peas, green beans\n",
      "Cilantro: parsley, basil, dill\n",
      "Apricot preserves: fig jam, quince jelly\n",
      "\n",
      "Please provide:\n",
      "1. List of ingredients with measurements\n",
      "2. Step-by-step instructions\n",
      "3. Any tips or variations\n",
      "\n",
      "Format the recipe clearly with sections for ingredients and instructions.\n",
      "[/INST]\n",
      "\n",
      "### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I am allergic to soy and eat vegan. Can you share a recipe for a protein-rich main dish using legumes instead of soy products?\n",
      "ALLERGIES TO AVOID: soy\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "14. Add cilantro, season with salt, and toss.\n",
      "15. In a small bowl, whisk apricot preserves, water, vinegar, red pepper flakes, and salt.\n",
      "16. Serve tofu with snap pea salad and apricot dipping sauce.\n",
      "Allergens: [Cow's Milk, Eggs, Coconut]\n",
      "Diet Types: [(Vegan,90),(Vegetarian,90),(\n"
     ]
    }
   ],
   "source": [
    "# allergy = Soy / cousine = Vegan\n",
    "# Example Usage\n",
    "query = \"I am allergic to soy and eat vegan. Can you share a recipe for a protein-rich main dish using legumes instead of soy products?\"\n",
    "response = query_recipes(query, vectorstore, allergens_dict)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b6eb5a1-8aaa-45f4-8ca0-a91ea58ae3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allergens found in query: ['fish', 'shellfish']\n",
      "Found 20 relevant recipes\n",
      "Filtered to 7 documents after removing allergen-containing content\n",
      "\n",
      "Generating recipe...\n",
      "Raw response: [{'generation': \"\\n\\n### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I have a food allergy to dairy. Can you provide a recipe for a meat-based stew that doesn't contain dairy?\\nALLERGIES TO AVOID: dairy\\n\\nHere are some relevant recipes for reference:\\nNote: You can adjust the amount of soy sauce and rice vinegar to your taste. Also, you can add other seasonings such as garlic or chili flakes to the sauce if you prefer.\\nAllergens: [Soy, Allium, Sugar]\\nDiet Types: [(Vegan,90),(Asian,80),(Gluten-Free,70),(Dairy-Free,60),(Lactovegetarians,50)]\\nCuisine: Japanese\\nMeal Type: Main Course\\nAlternative Ingredients: Soy sauce: tamari, coconut aminos\\nRice wine vinegar: balsamic vinegar, apple cider vinegar\\nGinger: turmeric, galangal\\nGreen onion: scallions, chives\\nGarlic: shallots, leeks\\nSugar: maple syrup, honey\\nSesame oil: sunflower oil, canola oil\\n\\nPlease provide:\\n1. List of ingredients with measurements\\n2. Step-by-step instructions\\n3. Any tips or variations\\n\\nFormat the recipe clearly with sections for ingredients and instructions.\\n[/INST]\\n\\n### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\\n\\nREQUEST: I have a food allergy to dairy. Can you provide a recipe for a meat-based stew that doesn't contain dairy?\\nALLERGIES TO AVOID: dairy\\n\\nHere are some relevant recipes for reference:\\nNote: You can adjust the amount of soy sauce and rice vinegar to your taste. Also, you can add other seasonings such as garlic or chili flakes to the sauce if you prefer.\\nAllergens: [Soy, Allium, Sugar]\\nDiet Types: [(Vegan,90),(Asian,80),(Gluten-Free,70),(Dairy-Free,60),(Lactovegetarians,50)]\\nCuisine: Japanese\\nMeal Type: Main Course\\nAlternative Ingredients: Soy sauce: tamari, coconut aminos\\nRice wine vinegar: balsamic vinegar, apple cider vinegar\\nGinger: turmeric, galangal\\nGreen onion: scallions, chives\\nGarlic: shallots, leeks\\nSugar: maple syrup, honey\\nSesame oil: sunflower oil, canola oil\\n\\nPlease provide:\\n1. List of ingredients with measurements\\n2. Step-by-step instructions\\n3. Any tips or variations\\n\\nFormat\"}]\n",
      "\n",
      "Response received, length: 2065\n",
      "### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I have a food allergy to dairy. Can you provide a recipe for a meat-based stew that doesn't contain dairy?\n",
      "ALLERGIES TO AVOID: dairy\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "Note: You can adjust the amount of soy sauce and rice vinegar to your taste. Also, you can add other seasonings such as garlic or chili flakes to the sauce if you prefer.\n",
      "Allergens: [Soy, Allium, Sugar]\n",
      "Diet Types: [(Vegan,90),(Asian,80),(Gluten-Free,70),(Dairy-Free,60),(Lactovegetarians,50)]\n",
      "Cuisine: Japanese\n",
      "Meal Type: Main Course\n",
      "Alternative Ingredients: Soy sauce: tamari, coconut aminos\n",
      "Rice wine vinegar: balsamic vinegar, apple cider vinegar\n",
      "Ginger: turmeric, galangal\n",
      "Green onion: scallions, chives\n",
      "Garlic: shallots, leeks\n",
      "Sugar: maple syrup, honey\n",
      "Sesame oil: sunflower oil, canola oil\n",
      "\n",
      "Please provide:\n",
      "1. List of ingredients with measurements\n",
      "2. Step-by-step instructions\n",
      "3. Any tips or variations\n",
      "\n",
      "Format the recipe clearly with sections for ingredients and instructions.\n",
      "[/INST]\n",
      "\n",
      "### [INST] You are a helpful cooking assistant. Create a recipe based on this request:\n",
      "\n",
      "REQUEST: I have a food allergy to dairy. Can you provide a recipe for a meat-based stew that doesn't contain dairy?\n",
      "ALLERGIES TO AVOID: dairy\n",
      "\n",
      "Here are some relevant recipes for reference:\n",
      "Note: You can adjust the amount of soy sauce and rice vinegar to your taste. Also, you can add other seasonings such as garlic or chili flakes to the sauce if you prefer.\n",
      "Allergens: [Soy, Allium, Sugar]\n",
      "Diet Types: [(Vegan,90),(Asian,80),(Gluten-Free,70),(Dairy-Free,60),(Lactovegetarians,50)]\n",
      "Cuisine: Japanese\n",
      "Meal Type: Main Course\n",
      "Alternative Ingredients: Soy sauce: tamari, coconut aminos\n",
      "Rice wine vinegar: balsamic vinegar, apple cider vinegar\n",
      "Ginger: turmeric, galangal\n",
      "Green onion: scallions, chives\n",
      "Garlic: shallots, leeks\n",
      "Sugar: maple syrup, honey\n",
      "Sesame oil: sunflower oil, canola oil\n",
      "\n",
      "Please provide:\n",
      "1. List of ingredients with measurements\n",
      "2. Step-by-step instructions\n",
      "3. Any tips or variations\n",
      "\n",
      "Format\n"
     ]
    }
   ],
   "source": [
    "# allergy = Fish & Crustacean / cousine = Japanese\n",
    "# Example Usage\n",
    "query = \"I have seafood allergies (fish and shellfish). Can you provide a recipe for vegetable tempura with a dipping sauce that doesn't contain dashi or fish sauce?\"\n",
    "response = query_recipes(query, vectorstore, allergens_dict)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7e26e-0b9d-4623-bc98-1b66654b543a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe5160-523a-40fa-aed5-6cc232f79344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6b12b-56c5-48df-90a2-5a68986861e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de336e7-6f78-43f0-a5aa-9f35dd702666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5003b56-27ea-4571-baba-493e7c42af67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69af0c-2728-4cc3-8ef1-ea71a9d2278d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53230758-af2b-4e44-8229-467d4de2dff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a60a2-3558-48d9-80d8-34047fe0e090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4792b44-1c52-49ee-a755-a696584d2c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a4586-773e-4024-9bbc-ed04f64618b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc80c16-b5a8-48da-bbfb-58a1085eda94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
