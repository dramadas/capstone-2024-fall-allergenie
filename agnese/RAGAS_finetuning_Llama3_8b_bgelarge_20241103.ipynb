{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw_peXtlRhm9",
        "outputId": "dccd27a0-f68b-4eba-a74c-4eff77cb887d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall openai -y\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4umUYkkSCdj",
        "outputId": "1cae397a-bf4c-407e-a2ec-503aff51e30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: openai 1.52.2\n",
            "Uninstalling openai-1.52.2:\n",
            "  Successfully uninstalled openai-1.52.2\n",
            "Collecting openai\n",
            "  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-1.53.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj9D-ZRYSKNb",
        "outputId": "110a50b9-2928-48d9-805b-4e604d12019a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.53.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Assuming you have your API key stored in an environment variable.\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\", \"sk-\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "try:\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Hello, how are you?'\"},\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        "        ],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    )\n",
        "    # Accessing the content of the message directly from the choices object\n",
        "    response_content = chat_completion.choices[0].message.content.strip()\n",
        "    print(response_content)\n",
        "except Exception as e:\n",
        "    print(\"Error occurred:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEjdPjK1SQBH",
        "outputId": "3e4043e0-903a-4207-f3cd-890f5199161b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour, comment vas-tu ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ragas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWJTF_7vSqNl",
        "outputId": "a1d545f8-7e2c-41ba-df67-5cdcd8a1e51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ragas\n",
            "  Downloading ragas-0.2.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ragas) (1.26.4)\n",
            "Collecting datasets (from ragas)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting tiktoken (from ragas)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from ragas) (0.3.4)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (from ragas) (0.3.13)\n",
            "Collecting langchain-community (from ragas)\n",
            "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai (from ragas)\n",
            "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas) (1.6.0)\n",
            "Collecting appdirs (from ragas)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from ragas) (2.9.2)\n",
            "Requirement already satisfied: openai>1 in /usr/local/lib/python3.10/dist-packages (from ragas) (1.53.0)\n",
            "Collecting pysbd>=0.3.4 (from ragas)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ragas) (2.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.32.3)\n",
            "Collecting xxhash (from datasets->ragas)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->ragas)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (2.0.36)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (0.1.137)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core->ragas) (1.33)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain->ragas)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->ragas)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community->ragas)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain (from ragas)\n",
            "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core (from ragas)\n",
            "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->ragas)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->ragas) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->ragas) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->ragas) (0.2.0)\n",
            "Downloading ragas-0.2.3-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.5-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: appdirs, xxhash, SQLAlchemy, python-dotenv, pysbd, mypy-extensions, marshmallow, httpx-sse, fsspec, dill, typing-inspect, tiktoken, multiprocess, pydantic-settings, dataclasses-json, langchain-core, langchain-openai, datasets, langchain, langchain-community, ragas\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.13\n",
            "    Uninstalling langchain-core-0.3.13:\n",
            "      Successfully uninstalled langchain-core-0.3.13\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.4\n",
            "    Uninstalling langchain-0.3.4:\n",
            "      Successfully uninstalled langchain-0.3.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SQLAlchemy-2.0.35 appdirs-1.4.4 dataclasses-json-0.6.7 datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 httpx-sse-0.4.0 langchain-0.3.7 langchain-community-0.3.5 langchain-core-0.3.15 langchain-openai-0.2.5 marshmallow-3.23.1 multiprocess-0.70.16 mypy-extensions-1.0.0 pydantic-settings-2.6.1 pysbd-0.3.4 python-dotenv-1.0.1 ragas-0.2.3 tiktoken-0.8.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v063AG2YHHY",
        "outputId": "ae3a1338-1192-443c-c470-bc3a5c5c1762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwffvhuMYwb3",
        "outputId": "635e7c2d-37c9-4eb2-a7a7-4ee97be479d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.17.0 textstat-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsJoXBCEZI3K",
        "outputId": "9ffda2fc-1719-48f9-c7bb-e4ad2c6ab85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=0b8bd9b1a191476ce6ae41d1262e7b3e07c00b8343e60ebee42932c36c9f4a75\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file path for generated recipe\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/Notebooks_Finetuning/generated_recipes_new.txt'"
      ],
      "metadata": {
        "id": "bQAj9VxQVctj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the correct file path for generated recipe\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/Notebooks_Finetuning/RAGAS_old dataset_medium/generated_recipes_new.txt'\n",
        "\n",
        "# Load the generated_recipes_new.txt file to verify content\n",
        "with open(file_path, 'r') as file:\n",
        "    generated_recipes_new = file.readlines()\n",
        "\n",
        "print(\"Sample recipes:\\n\", generated_recipes_new[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpxO9FsDT2E4",
        "outputId": "a70a54e4-41e9-4284-9d6e-c251900a7967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample recipes:\n",
            " ['\\n', '=== Scenario 1, Recipe 1 ===\\n', '\\n', 'Query: I am allergic to nuts and tree nuts. Can you give me a Thai curry recipe free of nuts?\\n', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List of Allergies\n",
        "milk_allergy = [\"artificial butter\",  \"flavor\", \"butter\", \"butter fat\", \"butter oil\", \"caseinates\", \"cheese\", \"cottage cheese\", \"cream\", \"custard\",\n",
        "                \"pudding\", \"ghee\", \"half and half\", \"hydrolysates\", \"lactalbumin\", \"lactalbumin phosphate\", \"lactoglobulin\", \"lactoferrin\", \"lactose\",\n",
        "                \"lactulose\", \"milk\", \"milk derivative\", \"milk protein\", \"milk solids\", \"malted milk\", \"condensed milk\", \"evaporated milk\", \"dry milk\",\n",
        "                \"whole milk\", \"low-fat milk\", \"nonfat milk\", \"skim milk\", \"goat's milk\", \"A2 milk\", \"Nisin\", \"Nougat\", \"Recaldent\", \"rennet casein\", \"sour cream\", \"sour cream solids\",\n",
        "                \"whey\", \"yogurt\", \"brown sugar flavoring\", \"caramel flavoring\", \"chocolate\", \"high protein flour\", \"lactose\", \"luncheon meats\", \"hot dogs\", \"sausages\", \"margarine\", \"simplesse\"]\n",
        "\n",
        "egg_allergy = [\"egg\", \"albumin\", \"egg whites\", \"egg yolk\", \"dried egg\", \"egg powder\", \"egg solids\", \"egg substitutes\", \"eggnog\", \"fat substitutes\",\n",
        "               \"globulin\", \"livetin\", \"lysozyme\", \"mayonnaise\", \"meringue\", \"ovalbumin\", \"ovomucin\", \"ovomucoid\", \"ovovitellin\", \"surimi\", \"lecithin\",\n",
        "               \"macaroni\", \"marzipan\", \"marshmallows\", \"nougat\", \"pasta\", \"ice cream\", \"cake icing\", \"frosting\",\n",
        "               \"fat substitutes\", \"egg whites\", \"eggshells\", \"soup stocks\", \"consommés\", \"bouillons\", \"coffees\"]\n",
        "\n",
        "fish_allergy = [\"fish\", \"anchovies\", \"bass\", \"catfish\", \"cod\", \"flounder\", \"grouper\", \"haddock\", \"hake\", \"halibut\", \"herring\", \"mahi mahi\",\n",
        "                \"perch\", \"pike\", \"pollock\", \"salmon\", \"scrod\", \"sole\", \"snapper\", \"swordfish\", \"tilapia\", \"trout\", \"tuna\", \"snapper\", \"swordfish\",\n",
        "                \"fish flavoring\", \"fish gelatin\", \"fish oil\", \"fish sticks\", \"barbecue sauce\", \"bouillabaisse\", \"caesar salad\", \"caesar dressing\",\n",
        "                \"caponata\", \"imitation fish\", \"artificial fish\", \"artificial shellfish\", \"worcestershire sauce\"]\n",
        "\n",
        "shellfish_allergy = [\"shellfish\", \"abalone\", \"barnacle\", \"krill\", \"clams\", \"cherrystone\", \"littleneck\", \"pismo\", \"quahog\", \"crab\", \"crawfish\", \"crayfish\", \"écrevisse\",\n",
        "                     \"crawdad\", \"lobster\", \"langouste\", \"langoustine\", \"scampi\", \"coral\", \"tomalley\", \"mollusks\", \"Mussels\", \"squid\", \"calamari\", \"snail\", \"escargot\",\n",
        "                     \"oysters\", \"octopus\", \"scallops\", \"shrimp\", \"prawns\", \"crevette\", \"bouillabaisse\", \"cuttlefish ink\", \"fish stock\", \"fish sauce\", \"seafood flavoring\", \"glucosamine\", \"surimi\"]\n",
        "\n",
        "treenut_allergy = [\"treenut\", \"almonds\", \"beechnuts\", \"brazil nuts\", \"butternuts\", \"cashews\", \"chestnuts\", \"coconut\", \"filberts\", \"hazelnuts\",\n",
        "                   \"gingko nuts\", \"hickory nuts\", \"lychee nuts\", \"macadamia nuts\", \"pecans\", \"pine nuts\", \"pignolia\", \"pistachios\",\n",
        "                   \"walnuts\", \"caponata\", \"gianduja\", \"marzipan paste\", \"almond paste\", \"natural nut extract\", \"nougat\", \"artificial nuts\",\n",
        "                   \"nut butters\", \"cashew butter\", \"almond butter\", \"chocolate Hazelnut spread\", \"nut oil\", \"nut pastes\", \"almond paste\",\n",
        "                   \"pesto\", \"praline\"]\n",
        "\n",
        "peanut_allergy = [\"peatnut\", \"artificial nuts\", \"beer nuts\", \"ground nuts\", \"mixed nuts\", \"monkey nuts\", \"peanut butter\", \"peanut flour\",\n",
        "                  \"peanut oil\", \"cereal\", \"chili\", \"spaghetti sauce\", \"crackers\", \"egg rolls\", \"enchilada sauce\", \"flavoring\", \"hydrolyzed plant protein\",\n",
        "                  \"hydrolyzed vegetable protein\", \"Ice creams\", \"frozen yogurts\", \"nondairy frozen desserts\", \"marzipan\", \"nougat\"]\n",
        "\n",
        "wheat_allergy = [\"wheat\", \"bran\", \"bread crumbs\", \"bulgur\", \"cereal extract\", \"couscous\", \"cracker meal\", \"durum\", \"einkorn\", \"emmer\", \"farina\",\n",
        "                 \"flour\", \"enriched flour\", \"graham flour\", \"high-gluten flour\", \"high gluten flour\", \"high-protein flour\", \"high protein flour\", \"whole-wheat flour\", \"whole wheat flour\",\n",
        "                 \"matzoh\", \"matzoh meal\", \"pasta\", \"seitan\", \"semolina\", \"spelt\", \"vital gluten\", \"wheat berries\", \"germ\", \"gluten\", \"grass\", \"malt\", \"sprouted\", \"starch\", \"gelatinized starch\",\n",
        "                 \"gum\", \"hydrolyzed vegetable protein\", \"kamut\", \"modified food starch\", \"modified starch\", \"natural flavoring\", \"soy sauce\", \"starch\", \"Surimi\", \"vegetable starch\"]\n",
        "\n",
        "soy_allergy = [\"soy\", \"hydrolyzed soy protein\", \"miso\", \"edamame\", \"natto\", \"soy albumin\", \"soy cheese\", \"soy fiber\", \"soy yogurt\",\n",
        "               \"soy ice cream\", \"soy bean\", \"shoyu\", \"soy flour\", \"soy grits\", \"soy nuts\", \"soy milk\", \"soy sprouts\",\n",
        "               \"soy protein concentrate\", \"soy protein isolate\", \"soy protein hydrolyzed\", \"soy sauce\", \"tamari\", \"tempeh\", \"textured vegetable protein\", \"TVP\",\n",
        "               \"tofu\", \"hydrolyzed plant protein\", \"hydrolyzed vegetable protein\", \"natural flavoring\", \"vegetable broth\", \"vegetable gum\", \"vegetable starch\",\n",
        "               \"Vitamin E\"]"
      ],
      "metadata": {
        "id": "e_94JJ8bbPuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gold Answer (GA)\n",
        "scenario_one = [\"Shrimp Red Thai Curry \\n\\n **Ingredients** \\n\\n 2 (14 ounce) cans coconut milk \\n\\n 2 tablespoons red Thai curry paste \\n\\n 1 tablespoon fish sauce \\n\\n 1 fresh red chili pepper, seeded and minced \\n\\n 24 large shrimp, peeled and deveined \\n\\n **Instructions** \\n\\n In a wok, combine coconut milk, curry paste, fish sauce, and minced pepper. Slowly bring to a simmer over medium low heat, stirring frequently.\\nReduce heat to low, and add shrimp. Cook uncovered, stirring frequently, until prawns are cooked and flavors mellow, about 15 minutes.\",\n",
        "                \"Coconut Curry Tofu \\n\\n   **Ingredients** \\n\\n 2 bunches green onions, 1 (14 ounce) can light coconut milk, 1/4 cup soy sauce, divided, 1/2 teaspoon brown sugar, 1 1/2 teaspoons curry powder, 1 teaspoon minced fresh ginger, 2 teaspoons chile paste, 1 pound firm tofu, cut into 3/4 inch cubes, 4 roma (plum) tomatoes, chopped, 1 yellow bell pepper, thinly sliced, 4 ounces fresh mushrooms, chopped, 1/4 cup chopped fresh basil, 4 cups chopped bok choy, salt to taste \\n\\n **Instructions** \\n\\n Remove white parts of green onions, and finely chop. Chop greens into 2 inch pieces.\\nIn a large heavy skillet over medium heat, mix coconut milk, 3 tablespoons soy sauce, brown sugar, curry powder, ginger, and chile paste. Bring to a boil.\\nStir tofu, tomatoes, yellow pepper, mushrooms, and finely chopped green onions into the skillet. Cover, and cook 5 minutes, stirring occasionally. Mix in basil and bok choy. Season with salt and remaining soy sauce. Continue cooking 5 minutes, or until vegetables are tender but crisp. Garnish with remaining green onion.\",\n",
        "                \"Baingan Bharta (Eggplant Curry) \\n\\n **Ingredients** \\n\\n 1 large eggplant, 2 tablespoons vegetable oil, 1 teaspoon cumin seeds, 1 medium onion, thinly sliced, 1 tablespoon ginger garlic paste,1 tablespoon curry powder, 1 tomato, diced, 1/2 cup plain yogurt, 1 fresh jalapeno chile pepper, finely chopped, 1 teaspoon salt, 1/4 bunch cilantro, finely chopped \\n\\n **Instructions** \\n\\n Preheat oven to 450 degrees F (230 degrees C).\\nPlace eggplant on a medium baking sheet. Bake 20 to 30 minutes in the preheated oven, until tender. Remove from heat, cool, peel, and chop.\\nHeat oil in a medium saucepan over medium heat. Mix in cumin seeds and onion. Cook and stir until onion is tender.\\nMix ginger garlic paste, curry powder, and tomato into the saucepan, and cook about 1 minute. Stir in yogurt. Mix in eggplant and jalapeno pepper, and season with salt. Cover, and cook 10 minutes over high heat. Remove cover, reduce heat to low, and continue cooking about 5 minutes. Garnish with cilantro to serve.\",\n",
        "                \"Vegetable Curry with Fried Rice \\n\\n Vegetable Curry with Fried Rice 12 shallots, chopped 2 tablespoons chopped garlic 2 tablespoons chopped ginger 1 tablespoon turmeric powder or 2-inches fresh turmeric root, peeled 1/2 cup macadamia nuts 1 teaspoon shrimp paste (optional) 1/2 cup chopped lemongrass 1 tablespoon ground coriander 1 teaspoon ground Thai Bird chile 1 tablespoon tomato paste 2 tablespoons tamarind pulp, soaked in 1-cup warm water, strained, pulp discarded 3 kaffir lime leaves, stemmed and cut 1/16-inch ribbon 1 cup vegetable stock 1 cup coconut milk 1 cup cauliflower florets, blanched in salted water and cooled in an ice bath 1 cup mixed yellow and green patty pan squash, halved, blanched in salted water and cooled in an ice bath 2 cups mixed yellow and green squash, cut into 2-inch chunks and blanched in salted water and cooled in an ice bath 1 cup haricot verts, snipped and blanched in salted water and cooled in an ice bath 2 chayotes, cut into 2 inch chunks and blanched in salted water and cooled in an ice bath Grapeseed oil, to cook Salt and pepper Nasi Goreng, recipe follows Fried Shallots, recipe follows Peanut oil, for cooking 8 shallots, halved and sliced 4 cloves garlic, sliced 1 tablespoon minced ginger, 1 tablespoon minced lemongrass, white part only 1/4 cup sambal oelek 2 tablespoons naturally brewed soy sauce 4 eggs, beaten 2 cups cooked jasmine or other long grain rice, cold 2 cups cooked Balinese red rice, cold (can substitute jasmine or other long grain rice) 2 Thai bird chiles, minced 1/4 cup chopped cilantro Peanut oil, for frying 1 cup sliced shallots 1/2 cup rice flour Salt Preheat a fryer or deep pot of oil to 350 degrees F. Instructions: 1. In a food processor, puree the shallots, garlic, ginger, turmeric, nuts, shrimp paste, lemongrass, coriander, chile, tomato paste, and tamarind juice until smooth. 2. Prepare a hot skillet coated with oil and add the pureed mixture, cooking for 5 minutes. 3. Add kaffir lime leaves, stock, and coconut milk, simmering for 10 minutes. 4. Remove kaffir lime leaves and season with salt and pepper. Mix in blanched vegetables and heat thoroughly. 5. In a large pasta bowl, fill with rice and top with vegetable curry. Garnish with fried shallots. 6. In a wok on high heat, coat lightly with oil and stir-fry shallots and garlic until lightly browned. 7. Add ginger, lemongrass, sambal, soy, and eggs, mixing quickly. 8. Add rice, chiles, and cilantro, seasoning with salt and pepper as needed. 9. Toss shallots with flour and fry in 350°F fryer until crispy. Drain on paper towels and season with salt.\",\n",
        "                \"Thai Green Curry Meatballs with Zoodles 3 tablespoons vegetable oil 3 tablespoons Thai green curry paste Two 13.5-ounce cans coconut milk One 14-ounce bag plain frozen meatballs, thawed Kosher salt and freshly ground black pepper Two 16-ounce packages fresh zucchini noodles (zoodles) 1 red Thai bird chile, sliced very thin on the bias 1/2 cup fresh basil leaves 1/2 cup fresh cilantro leaves 2 teaspoons toasted black sesame seeds 2 teaspoons toasted white sesame seeds 1 lime, cut into wedges Instructions: 1. Heat oil in a large saucepan or wide pot over medium heat. 2. Add curry paste and bloom in the oil, stirring frequently, for 2 minutes. 3. Stir in coconut milk and bring to a simmer. 4. Add thawed meatballs and continue to simmer, stirring frequently, for 3 to 5 minutes. 5. Season with salt and pepper to taste. 6. Heat remaining oil in another large pan over medium-high heat. 7. Add zoodles and cook, stirring occasionally, for 5 minutes. 8. Evenly divide zoodles among 4 bowls. 9. Ladle curry over zoodles and top each with a few meatballs. 10. Top each with sliced Thai bird chiles, basil, cilantro and black and white sesame seeds. 11. Serve with lime wedges.\",\n",
        "                \"Coconut Curry Shrimp One 14-ounce can unsweetened coconut milk (not low-fat) 1 tablespoon fresh lime juice 1 tablespoon curry powder 2 teaspoons minced ginger Salt and freshly ground black pepper 1 pound large shrimp, peeled and deveined Lime wedges, for serving Instructions: 1. In a large pot, whisk together coconut milk, lime juice, curry powder, and ginger. 2. Bring the mixture to a low boil over low heat, slowly and simmer for about 7-10 minutes or until slightly reduced and thickened. 3. Taste for seasoning and add salt and/or pepper as needed. 4. Add the shrimp and continue to simmer, covered, until the shrimp are fully cooked, about 12-15 minutes. 5. Transfer the curry to a serving bowl and serve with lime wedges.\",\n",
        "                \"Green Curry with Shrimp 4 tablespoons peanut oil 1 pound 16/20-count shrimp, deveined and shells removed 1 small yellow onion, sliced thin 1 jalapeno, sliced thin Kosher salt 2 to 3 tablespoons Thai green curry paste 1/2 cup chicken stock One 15-ounce can coconut milk 2 teaspoons fish sauce 1 tablespoon palm sugar or light brown sugar 1 tablespoon fresh basil leaves, sliced thin 1 tablespoon fresh mint leaves, sliced thin 1/4 cup roasted salted peanuts, roughly chopped Steamed rice, for serving Instructions: 1. Heat oil in a large nonstick skillet over medium-high heat. 2. Add shrimp and par-cook by searing each side for about 1 minute. 3. Remove shrimp to a plate and set aside. 4. Add remaining oil and onions, jalapenos, salt, and cook until browned, 5 to 6 minutes. 5. Add green curry paste and stir to combine, cooking for another 30 seconds. 6. Add chicken stock, coconut milk, fish sauce, and sugar, stirring to combine. 7. Bring mixture to a simmer and cook until thickened, about 10 minutes. 8. Add shrimp back to the curry and cook until cooked through, 1 to 2 minutes. 9. Ladle curry into a serving bowl and garnish with basil, mint, and peanuts. 10. Serve with steamed rice - a perfect combination.\",\n",
        "                \"Thai Curry Tofu \\n\\n **Ingredients** \\n\\n 1 tablespoon canola oil, 1 (12 ounce) package extra-firm tofu, drained and cubed, 1 tablespoon seasoned salt, or to taste, 1 tablespoon butter or margarine, 1 small onion, chopped, 3 cloves garlic, minced, 1 (10 ounce) can coconut milk, 2 teaspoons curry powder, 1/2 teaspoon salt, 1/4 teaspoon ground black pepper, 1/4 cup chopped fresh cilantro **Instructions** \\n\\n Heat oil in a large skillet over medium-high heat. Add tofu cubes, season with seasoned salt and fry until golden on all sides, stirring occasionally, about 15 minutes. Remove to paper towels, and set aside.\\nMelt butter or margarine in the same skillet over medium heat. Add the onion and garlic; cook and stir until tender. Stir in coconut milk, curry powder, salt, pepper and cilantro. Return the tofu to the skillet. Simmer over low heat for 15 minutes, stirring occasionally.\",\n",
        "                \"Thai Curry Chicken and Rice \\n\\n **Ingredients** \\n\\n 1 tablespoon canola oil, 2 tablespoons green curry paste,1 pound boneless skinless chicken breasts, cut into bite-size pieces,1 small onion, thinly sliced,1 red pepper, cut into thin strips, then cut crosswise in half, 1 green pepper, cut into thin strips, then cut crosswise in half, 4 ounces PHILADELPHIA Cream Cheese, cubed,1/4 cup milk,1/8 teaspoon white pepper, 2 cups hot cooked long-grain white rice \\n\\n **Instructions** \\n\\n Heat oil in large nonstick skillet on medium heat. Stir in curry paste until well blended. Add chicken and onions; cook and stir 6 to 8 min. or until chicken is done (165 degrees F). Stir in red and green peppers; cook 4 to 5 min. or until crisp-tender.\\nAdd cream cheese, milk and white pepper; cook until cream cheese is melted and evenly coats chicken and vegetables, stirring frequently.\\nServe over rice.\\n\",\n",
        "                \"Marinated Shrimp in Red Curry 1 (14-ounce) can unsweetened coconut milk 2 tablespoons red curry paste 1/2 red onion, peeled and finely chopped 1/4 cup chopped fresh cilantro leaves 1 lime, juiced 2 to 3 tablespoons canola oil Salt and freshly ground pepper 2 pounds shrimp, shell and tail left on Instructions: 1. Heat grill to high. 2. Whisk together coconut milk, curry paste, onion, cilantro, lime juice, and oil in a large bowl. 3. Season, to taste, with salt and pepper. 4. Place shrimp in the bowl and toss to coat. 5. Cover and let marinate at room temperature for 20 minutes. 6. Remove shrimp from the marinade and grill for 1 1/2 to 2 minutes per side. 7. Serve on brown paper bags, if desired.\",\n",
        "                \"Green Curry Shrimp 8 lime wedges, garnish 2 tablespoons vegetable oil 2 cups diced eggplant (1/2-inch dice) 1/2 cup chopped white onions 1 cup thinly sliced green bell peppers 2 teaspoons minced garlic 2 to 4 tablespoons Thai green curry paste, depending on desired degree of heat 6 Kaffir lime leaves, or 1 tablespoon finely grated lime zest 2 tablespoons nam pla (Thai fish sauce) 1 (14-ounce) can unsweetened coconut milk 1 cup shrimp stock, fish stock or bottled clam juice 1 1/2 pounds medium shrimp, peeled and deveined 1/2 cup chopped Thai basil (if unavailable use 1/2 Italian basil, 1/2 mint) 1/4 teaspoon salt Steamed white rice, accompaniment Instructions: 1. Heat oil in a wok or large saute pan over medium-high heat. 2. Add eggplant, onions, and bell pepper and cook until softened, 3 to 5 minutes. 3. Add garlic and cook, stirring, until fragrant, about 30 seconds. 4. Add curry paste, lime leaves, and fish sauce, and cook, stirring, for 15 seconds. 5. Add coconut milk and shrimp stock and bring to a boil. 6. Lower the heat and simmer until thickened, 3 minutes. 7. Add shrimp and cook until pink, about 2 minutes. 8. Stir in 1/4 cup of Thai basil and remove from heat. 9. Season to taste with salt. 10. Garnish with remaining 1/4 cup Thai basil. 11. Serve with rice and lime wedges.\"]\n",
        "\n",
        "\n",
        "scenario_two = [\"Tomato Chicken Parmesan **Ingredients** 2 eggs, beaten \\n\\n 1 cup grated Parmesan cheese \\n\\n 7 ounces seasoned bread crumbs \\n\\n 6 skinless, boneless chicken breast halves \\n\\n 1 tablespoon vegetable oil \\n\\n 12 ounces pasta sauce \\n\\n 6 slices Monterey Jack cheese \\n\\n **Instructions** \\n\\n Preheat oven to 375 degrees F (190 degrees C). \\n\\n Pour beaten eggs into a shallow dish or bowl. In another shallow dish or bowl, mix together the grated Parmesan cheese and bread crumbs. Dip chicken breasts into beaten egg, then into bread crumb mixture to coat. \\n\\n In a large skillet, heat oil over medium high heat. Add coated chicken and saute for about 8 to 10 minutes each side, or until chicken is cooked through and juices run clear. \\n\\n Pour tomato sauce into a lightly greased 9x13 inch baking dish. Add chicken, then place a slice of Monterey Jack cheese over each breast, and bake in the preheated oven for 20 minutes or until cheese is completely melted.\"]\n",
        "\n",
        "\n",
        "scenario_three = [\"Pumpkin Brownies **Ingredients** \\n Brownie Mixture: \\n 1 box Enjoy Life Foods Brownie Mix \\n 3/4 cup cold water \\n 2 Tbsp mild olive oil or grapeseed oil \\n Pumpkin Mixture: \\n 1 1/4 cup mashed pumpkin \\n 1/4 cup pure maple syrup \\n 1/4 cup Enjoy Life Foods All-Purpose Flour \\n 1 tsp ground cinnamon \\n 1/2 tsp vanilla extract \\n 1/4 tsp ground nutmeg \\n 1/4 tsp ground ginger \\n 1 pinch ground cloves \\n 1 pinch salt \\n Topping: \\n 1/4 cup Enjoy Life Foods Mini Chips \\n 2 tsp mild olive oil or grapeseed oil \\n Preheat the oven to 375˚F. Line an 8×8-inch baking pan with parchment paper. \\n To make the brownies, put the Brownie Mix in a large bowl. Add the cold water and oil. Stir until well mixed. \\n Scrape the mixture into the prepared pan, smoothing evenly. Bake for 15 minutes. \\n While the brownies are baking, prepare the pumpkin mixture. Put the mashed pumpkin, maple syrup, All-Purpose Flour, cinnamon, vanilla extract, nutmeg, ginger, cloves, and salt in a large bowl. Briskly whisk until well combined. \\n After the brownies have baked for 15 minutes, remove from the oven. Dollop the pumpkin mixture onto the par-baked brownies, swirling throughout the batter. \\n Bake for an additional 35 to 40 minutes, until a toothpick inserted in the brownies comes out clean, and the pumpkin portions are firm to the touch. Let cool in the pan for at least 1 hour. \\n To prepare the topping, put the Mini Chips and oil in a microwave safe bowl. Microwave on high for 15 seconds and stir. Repeat in 10 second intervals until melted and smooth. Drizzle the chocolate mixture over the top of the brownies. \\n Carefully remove the brownies from the pan, then cut into squares. \\n Serve, storing leftovers in an airtight container in the refrigerator for up to 3 days, and any other leftovers to the freezer.\"]\n",
        "\n",
        "\n",
        "scenario_four = [\"Healthy Tofu Tacos with Mango Salsa \\n\\n **Ingredients** \\n\\n 1 mango - peeled, seeded, and chopped \\n\\n 2 avocados - peeled, pitted, and chopped \\n\\n 1 cup chopped tomato \\n\\n 1/2 cup diced red onion \\n\\n 1/2 cup diced red pepper \\n\\n 2 tablespoons chopped fresh flat-leaf parsley \\n\\n 2 tablespoons canola oil \\n\\n 2 tablespoons brown sugar \\n\\n 1 lime, juiced \\n\\n 1 teaspoon cider vinegar \\n\\n 1 dash hot pepper sauce, or to taste \\n\\n salt and ground black pepper to taste \\n\\n 8 taco shells \\n\\n 14 to 16 ounces of extra firm tofu \\n\\n 1 teaspoon ground black pepper \\n\\n 1 teaspoon paprika \\n\\n 1/2 teaspoon salt \\n\\n 2 tablespoons olive oil \\n\\n **instructions** \\n\\n Stir mango, avocado, tomato, red onion, red pepper, parsley, canola oil, brown sugar, lime juice, cider vinegar, hot pepper sauce, salt, and ground black pepper together in a bowl. Refrigerate salsa for at least 1 hour. \\n\\n Preheat oven to 325 degrees F (165 degrees C). \\n\\n Heat taco shells in preheated oven until crisp, about 5 minutes. \\n\\n Cube tofu, and season tofu with 1 teaspoon ground black pepper, paprika, and 1/2 teaspoon salt. \\n\\n Heat olive oil in a skillet over medium-high heat. Cook tofu in olive oil until browned, about 5 minutes.\\n\\n Place tofu cubes in taco shells and top with mango salsa.\"]\n",
        "\n",
        "\n",
        "scenario_five = [\"Gyoza (Japanese Potstickers) \\n\\n **Ingredients** \\n\\n 1/2 pound ground pork \\n\\n 1/2 head napa cabbage, shredded \\n\\n 1 egg \\n\\n 3 green onions, thinly sliced \\n\\n 1 (2 inch) piece fresh ginger, grated \\n\\n 1 tablespoon soy sauce \\n\\n 1 teaspoon sriracha sauce, or more to taste \\n\\n 1 small clove garlic, minced \\n\\n 1/4 teaspoon sesame oil \\n\\n 30 gyoza wrappers, or as needed \\n\\n 1 tablespoon vegetable oil, or as needed \\n\\n 1 cup water \\n\\n Dipping Sauce: \\n\\n 2 tablespoons soy sauce \\n\\n 2 tablespoons seasoned rice vinegar \\n\\n 1 1/2 teaspoons sesame oil \\n\\n 1 dash sriracha sauce, or to taste \\n\\n **Instructions** \\n\\n Combine ground pork, napa cabbage, egg, green onions, ginger, 1 tablespoon soy sauce, 1 teaspoon sriracha sauce, garlic, and 1/4 teaspoon sesame oil in a bowl.\\n\\n Arrange gyoza wrappers on a flat work surface. Place 1 teaspoon of pork mixture in the middle of each wrapper. Wet edges with your finger or a brush. Fold up sides to form a semicircle; pinch edges to seal.\\n\\n Heat oil in a heavy skillet over medium-high heat. Add 12 to 15 gyoza to the skillet. Cook until golden brown on the bottom, about 2 minutes. Pour in 1/2 cup water; cover and cook until water is absorbed, 5 to 7 minutes. Transfer gyoza to a plate. Repeat with remaining gyoza.\\n\\n Mix 2 tablespoons soy sauce, rice vinegar, 1 1/2 teaspoon sesame oil, and 1 dash sriracha sauce together to make dipping sauce. Serve dipping side alongside gyoza.\"]\n",
        "\n",
        "# Now we can create the reference scenarios list\n",
        "reference_scenarios = [scenario_one[0], scenario_two[0], scenario_three[0],\n",
        "                      scenario_four[0], scenario_five[0]]"
      ],
      "metadata": {
        "id": "ZLKzx39XU0Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precision with Reference"
      ],
      "metadata": {
        "id": "GpTtf-9FU_ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9n4p13uZCDT",
        "outputId": "0440344d-5c90-4321-b357-5d1b287faf47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Precision with Reference example from RAGAS website"
      ],
      "metadata": {
        "id": "6HD1gRhoi-Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nest_asyncio\n",
        "import time\n",
        "import asyncio\n",
        "from ragas import SingleTurnSample\n",
        "from ragas.metrics import LLMContextPrecisionWithReference\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Apply nest_asyncio to handle async code in Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Initialize the ChatOpenAI model with a timeout and your API key\n",
        "chat_model = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    openai_api_key=api_key,\n",
        "    request_timeout=30  # 30 seconds timeout for each API call\n",
        ")\n",
        "\n",
        "print(\"Initializing LLM wrapper...\")\n",
        "llm = LangchainLLMWrapper(langchain_llm=chat_model)\n",
        "\n",
        "print(\"Creating metric...\")\n",
        "context_precision = LLMContextPrecisionWithReference(llm=llm)\n",
        "\n",
        "print(\"Creating sample...\")\n",
        "sample = SingleTurnSample(\n",
        "    user_input=\"Where is the Eiffel Tower located?\",\n",
        "    retrieved_contexts=[\"The Eiffel Tower is located in Paris.\"],\n",
        "    reference=\"The Eiffel Tower is located in Paris.\"\n",
        ")\n",
        "\n",
        "async def evaluate_with_timeout(sample, timeout_seconds=60):\n",
        "    try:\n",
        "        print(f\"\\nStarting evaluation (timeout set to {timeout_seconds} seconds)...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(\"Making API calls to evaluate context precision...\")\n",
        "        # Use asyncio.wait_for to implement a timeout\n",
        "        score = await asyncio.wait_for(\n",
        "            context_precision.single_turn_ascore(sample),\n",
        "            timeout=timeout_seconds\n",
        "        )\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        print(f\"\\nEvaluation completed in {duration:.2f} seconds\")\n",
        "        print(f\"Context Precision Score: {score:.4f}\")\n",
        "        return score\n",
        "\n",
        "    except asyncio.TimeoutError:\n",
        "        print(f\"\\nEvaluation timed out after {timeout_seconds} seconds\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during evaluation: {str(e)}\")\n",
        "        print(\"\\nSample dictionary:\")\n",
        "        print(sample.to_dict())\n",
        "\n",
        "        print(\"\\nFull error traceback:\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "print(\"\\nStarting the evaluation process...\")\n",
        "# Run with a 60-second timeout\n",
        "result = await evaluate_with_timeout(sample, timeout_seconds=60)\n",
        "\n",
        "if result is not None:\n",
        "    print(\"\\nSuccessful evaluation!\")\n",
        "else:\n",
        "    print(\"\\nEvaluation failed or timed out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYOND8MKeKU5",
        "outputId": "cb1743cd-a9f6-4af0-ba3b-d96ad9d41dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing LLM wrapper...\n",
            "Creating metric...\n",
            "Creating sample...\n",
            "\n",
            "Starting the evaluation process...\n",
            "\n",
            "Starting evaluation (timeout set to 60 seconds)...\n",
            "Making API calls to evaluate context precision...\n",
            "\n",
            "Evaluation completed in 0.86 seconds\n",
            "Context Precision Score: 1.0000\n",
            "\n",
            "Successful evaluation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "from ragas import SingleTurnSample\n",
        "from ragas.metrics import (\n",
        "    LLMContextPrecisionWithReference,\n",
        "    ContextRelevancy\n",
        ")\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Apply nest_asyncio to handle async code in Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def clean_recipe_text(text: str) -> str:\n",
        "    \"\"\"Clean recipe text to focus on core content.\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    clean_text = []\n",
        "    in_ingredients = False\n",
        "    in_instructions = False\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "\n",
        "        if \"**Ingredients:**\" in line or \"**Ingredients**\" in line:\n",
        "            in_ingredients = True\n",
        "            in_instructions = False\n",
        "            clean_text.append(\"**Ingredients**\")\n",
        "            continue\n",
        "\n",
        "        if \"**Instructions:**\" in line or \"**Instructions**\" in line:\n",
        "            in_ingredients = False\n",
        "            in_instructions = True\n",
        "            clean_text.append(\"**Instructions**\")\n",
        "            continue\n",
        "\n",
        "        if line.startswith(\"**\") and \"Ingredients\" not in line and \"Instructions\" not in line:\n",
        "            in_ingredients = False\n",
        "            in_instructions = False\n",
        "\n",
        "        if in_ingredients and line:\n",
        "            if line.startswith(\"*\"):\n",
        "                clean_text.append(line.replace(\"*\", \"\").strip())\n",
        "            elif line and not line.startswith(\"**\"):\n",
        "                clean_text.append(line)\n",
        "\n",
        "        if in_instructions and line:\n",
        "            if line.strip() and not line.startswith(\"**\"):\n",
        "                clean_text.append(line)\n",
        "\n",
        "    return '\\n'.join(clean_text)\n",
        "\n",
        "async def evaluate_context_metrics(recipe_text: str, golden_answer: str):\n",
        "    \"\"\"Evaluate recipes using context-based metrics.\"\"\"\n",
        "\n",
        "    # Initialize OpenAI\n",
        "    chat_model = ChatOpenAI(\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        openai_api_key=\"sk-\"\n",
        "    )\n",
        "\n",
        "    # Create the wrapper\n",
        "    llm = LangchainLLMWrapper(langchain_llm=chat_model)\n",
        "\n",
        "    # Clean texts\n",
        "    clean_recipe = clean_recipe_text(recipe_text)\n",
        "    clean_golden = clean_recipe_text(golden_answer)\n",
        "\n",
        "    print(\"\\nCleaned Recipe Text:\")\n",
        "    print(\"----------------------------------------\")\n",
        "    print(clean_recipe)\n",
        "    print(f\"Length: {len(clean_recipe)} characters\")\n",
        "\n",
        "    print(\"\\nCleaned Golden Answer Text:\")\n",
        "    print(\"----------------------------------------\")\n",
        "    print(clean_golden)\n",
        "    print(f\"Length: {len(clean_golden)} characters\")\n",
        "\n",
        "    # Create the sample\n",
        "    sample = SingleTurnSample(\n",
        "        user_input=\"Give me a Thai curry recipe without nuts\",\n",
        "        retrieved_contexts=[clean_recipe],\n",
        "        reference=clean_golden\n",
        "    )\n",
        "\n",
        "    # Initialize metrics\n",
        "    context_precision = LLMContextPrecisionWithReference(llm=llm)\n",
        "    context_relevancy = ContextRelevancy(llm=llm)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Calculate Context Precision\n",
        "    print(\"\\nCalculating Context Precision...\")\n",
        "    try:\n",
        "        score = await context_precision.single_turn_ascore(sample)\n",
        "        results[\"Context Precision\"] = score\n",
        "        print(f\"Context Precision: {score:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating Context Precision: {str(e)}\")\n",
        "        results[\"Context Precision\"] = None\n",
        "\n",
        "    # Calculate Context Relevancy\n",
        "    print(\"\\nCalculating Context Relevancy...\")\n",
        "    try:\n",
        "        score = await context_relevancy.single_turn_ascore(sample)\n",
        "        results[\"Context Relevancy\"] = score\n",
        "        print(f\"Context Relevancy: {score:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating Context Relevancy: {str(e)}\")\n",
        "        results[\"Context Relevancy\"] = None\n",
        "\n",
        "    return results\n",
        "\n",
        "# Get Recipe 1\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Capstone/Notebooks_Finetuning/RAGAS_old dataset_medium/generated_recipes_new.txt'\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "scenarios = content.split(\"=== Scenario\")\n",
        "recipe_1 = scenarios[1].split(\"==================================================\")[0]\n",
        "\n",
        "# Run evaluation\n",
        "async def main():\n",
        "    print(\"Running evaluation with context metrics...\")\n",
        "    results = await evaluate_context_metrics(recipe_1, scenario_one[0])\n",
        "\n",
        "    print(\"\\nFinal Results Summary:\")\n",
        "    for metric, score in results.items():\n",
        "        if score is not None:\n",
        "            print(f\"{metric}: {score:.4f}\")\n",
        "        else:\n",
        "            print(f\"{metric}: Failed\")\n",
        "\n",
        "# Execute evaluation\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "gwb6Ncpji7uP",
        "outputId": "6221c6dd-8700-4237-b93a-98836a204704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ContextRelevancy' from 'ragas.metrics' (/usr/local/lib/python3.10/dist-packages/ragas/metrics/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-e3b65ab10de8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mragas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingleTurnSample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from ragas.metrics import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mLLMContextPrecisionWithReference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mContextRelevancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ContextRelevancy' from 'ragas.metrics' (/usr/local/lib/python3.10/dist-packages/ragas/metrics/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2x41P2-9lgGq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}